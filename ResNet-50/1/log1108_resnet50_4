[2021-11-07 13:47:08] args:Namespace(ablation_id=0, arch='resnet_50', batch_size=64, compress_rate=None, data_dir='/home/featurize/data', dataset='ImageNet', epochs=10, from_scratch=True, gpu=0, input_size=224, job_dir='/home/featurize/work/CCCrank5', lr=1e-05, lr_decay_step='10', momentum=0.9, num_workers=8, pretrained=False, resume='finally_pruned_model/resnet_50_1107_3.pt', save_id=22, start_cov=-1, weight_decay=0.0005)
[2021-11-07 13:47:09] loading checkpoint:finally_pruned_model/resnet_50_1107_3.pt
[2021-11-07 13:48:31] validate Loss: 0.9904 Acc@1: 75.03 Acc@5: 92.30 time: 82.0005
[2021-11-07 13:48:31] epoch 0 learning_rate 1e-05 
[2021-11-07 13:56:17] epoch[0](2000/20000) Loss: 1.0982 Acc@1: 74.32 Acc@5: 90.56 time: 466.4969
[2021-11-07 14:04:01] epoch[0](4000/20000) Loss: 1.0924 Acc@1: 74.48 Acc@5: 90.60 time: 463.2581
[2021-11-07 14:11:44] epoch[0](6000/20000) Loss: 1.0926 Acc@1: 74.53 Acc@5: 90.59 time: 463.3997
[2021-11-07 14:19:27] epoch[0](8000/20000) Loss: 1.0937 Acc@1: 74.48 Acc@5: 90.56 time: 463.2845
[2021-11-07 14:27:11] epoch[0](10000/20000) Loss: 1.0959 Acc@1: 74.43 Acc@5: 90.53 time: 463.2678
[2021-11-07 14:34:54] epoch[0](12000/20000) Loss: 1.0959 Acc@1: 74.43 Acc@5: 90.54 time: 463.3074
[2021-11-07 14:42:37] epoch[0](14000/20000) Loss: 1.0961 Acc@1: 74.45 Acc@5: 90.54 time: 463.2964
[2021-11-07 14:50:21] epoch[0](16000/20000) Loss: 1.0967 Acc@1: 74.44 Acc@5: 90.53 time: 463.5190
[2021-11-07 14:58:04] epoch[0](18000/20000) Loss: 1.0965 Acc@1: 74.43 Acc@5: 90.54 time: 463.5721
[2021-11-07 15:05:48] epoch[0](20000/20000) Loss: 1.0961 Acc@1: 74.42 Acc@5: 90.55 time: 463.4054
[2021-11-07 15:05:52] train    Loss: 1.0961 Acc@1: 74.43 Acc@5: 90.55 time: 4641.1574
[2021-11-07 15:07:24] validate Loss: 0.9933 Acc@1: 74.96 Acc@5: 92.25 time: 91.7251
[2021-11-07 15:07:24] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 15:07:24] epoch 1 learning_rate 1e-05 
[2021-11-07 15:15:10] epoch[1](2000/20000) Loss: 1.0972 Acc@1: 74.38 Acc@5: 90.52 time: 466.2685
[2021-11-07 15:22:54] epoch[1](4000/20000) Loss: 1.0942 Acc@1: 74.49 Acc@5: 90.54 time: 463.2468
[2021-11-07 15:30:37] epoch[1](6000/20000) Loss: 1.0953 Acc@1: 74.43 Acc@5: 90.52 time: 463.2903
[2021-11-07 15:38:20] epoch[1](8000/20000) Loss: 1.0963 Acc@1: 74.41 Acc@5: 90.52 time: 463.3945
[2021-11-07 15:46:04] epoch[1](10000/20000) Loss: 1.0980 Acc@1: 74.37 Acc@5: 90.51 time: 463.2304
[2021-11-07 15:53:47] epoch[1](12000/20000) Loss: 1.0971 Acc@1: 74.40 Acc@5: 90.52 time: 463.3291
[2021-11-07 16:01:30] epoch[1](14000/20000) Loss: 1.0976 Acc@1: 74.41 Acc@5: 90.52 time: 463.4475
[2021-11-07 16:09:13] epoch[1](16000/20000) Loss: 1.0961 Acc@1: 74.45 Acc@5: 90.54 time: 463.2006
[2021-11-07 16:16:57] epoch[1](18000/20000) Loss: 1.0976 Acc@1: 74.43 Acc@5: 90.52 time: 463.3117
[2021-11-07 16:24:40] epoch[1](20000/20000) Loss: 1.0974 Acc@1: 74.44 Acc@5: 90.52 time: 463.1868
[2021-11-07 16:24:44] train    Loss: 1.0974 Acc@1: 74.44 Acc@5: 90.52 time: 4640.1966
[2021-11-07 16:26:16] validate Loss: 0.9917 Acc@1: 74.97 Acc@5: 92.27 time: 91.7105
[2021-11-07 16:26:16] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 16:26:16] epoch 2 learning_rate 1e-05 
[2021-11-07 16:34:03] epoch[2](2000/20000) Loss: 1.0945 Acc@1: 74.51 Acc@5: 90.60 time: 466.4189
[2021-11-07 16:41:46] epoch[2](4000/20000) Loss: 1.0951 Acc@1: 74.51 Acc@5: 90.59 time: 463.2719
[2021-11-07 16:49:29] epoch[2](6000/20000) Loss: 1.0939 Acc@1: 74.51 Acc@5: 90.61 time: 463.2175
[2021-11-07 16:57:12] epoch[2](8000/20000) Loss: 1.0949 Acc@1: 74.45 Acc@5: 90.60 time: 463.3330
[2021-11-07 17:04:56] epoch[2](10000/20000) Loss: 1.0941 Acc@1: 74.46 Acc@5: 90.60 time: 463.3694
[2021-11-07 17:12:39] epoch[2](12000/20000) Loss: 1.0950 Acc@1: 74.44 Acc@5: 90.58 time: 463.2215
[2021-11-07 17:20:22] epoch[2](14000/20000) Loss: 1.0953 Acc@1: 74.44 Acc@5: 90.57 time: 463.3225
[2021-11-07 17:28:06] epoch[2](16000/20000) Loss: 1.0954 Acc@1: 74.44 Acc@5: 90.56 time: 463.3723
[2021-11-07 17:35:49] epoch[2](18000/20000) Loss: 1.0957 Acc@1: 74.45 Acc@5: 90.54 time: 463.2475
[2021-11-07 17:43:32] epoch[2](20000/20000) Loss: 1.0964 Acc@1: 74.44 Acc@5: 90.53 time: 463.2997
[2021-11-07 17:43:37] train    Loss: 1.0964 Acc@1: 74.44 Acc@5: 90.53 time: 4640.3704
[2021-11-07 17:45:09] validate Loss: 0.9922 Acc@1: 74.98 Acc@5: 92.33 time: 92.3301
[2021-11-07 17:45:09] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 17:45:09] epoch 3 learning_rate 1e-05 
[2021-11-07 17:52:56] epoch[3](2000/20000) Loss: 1.0907 Acc@1: 74.55 Acc@5: 90.58 time: 466.3128
[2021-11-07 18:00:39] epoch[3](4000/20000) Loss: 1.0885 Acc@1: 74.58 Acc@5: 90.62 time: 463.2587
[2021-11-07 18:08:22] epoch[3](6000/20000) Loss: 1.0903 Acc@1: 74.55 Acc@5: 90.59 time: 463.2746
[2021-11-07 18:16:05] epoch[3](8000/20000) Loss: 1.0915 Acc@1: 74.52 Acc@5: 90.58 time: 463.2400
[2021-11-07 18:23:49] epoch[3](10000/20000) Loss: 1.0927 Acc@1: 74.50 Acc@5: 90.58 time: 463.3535
[2021-11-07 18:31:32] epoch[3](12000/20000) Loss: 1.0927 Acc@1: 74.48 Acc@5: 90.59 time: 463.3137
[2021-11-07 18:39:15] epoch[3](14000/20000) Loss: 1.0930 Acc@1: 74.47 Acc@5: 90.58 time: 463.1460
[2021-11-07 18:46:58] epoch[3](16000/20000) Loss: 1.0931 Acc@1: 74.49 Acc@5: 90.57 time: 463.2260
[2021-11-07 18:54:42] epoch[3](18000/20000) Loss: 1.0931 Acc@1: 74.48 Acc@5: 90.58 time: 463.1816
[2021-11-07 19:02:25] epoch[3](20000/20000) Loss: 1.0929 Acc@1: 74.48 Acc@5: 90.58 time: 463.0795
[2021-11-07 19:02:29] train    Loss: 1.0930 Acc@1: 74.48 Acc@5: 90.58 time: 4639.7269
[2021-11-07 19:04:01] validate Loss: 0.9909 Acc@1: 75.03 Acc@5: 92.37 time: 91.6703
[2021-11-07 19:04:01] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 19:04:01] epoch 4 learning_rate 1e-05 
[2021-11-07 19:11:47] epoch[4](2000/20000) Loss: 1.0840 Acc@1: 74.66 Acc@5: 90.73 time: 466.3428
[2021-11-07 19:19:31] epoch[4](4000/20000) Loss: 1.0887 Acc@1: 74.59 Acc@5: 90.65 time: 463.3092
[2021-11-07 19:27:14] epoch[4](6000/20000) Loss: 1.0889 Acc@1: 74.61 Acc@5: 90.67 time: 463.2190
[2021-11-07 19:34:57] epoch[4](8000/20000) Loss: 1.0903 Acc@1: 74.59 Acc@5: 90.65 time: 463.2425
[2021-11-07 19:42:40] epoch[4](10000/20000) Loss: 1.0900 Acc@1: 74.59 Acc@5: 90.65 time: 463.2628
[2021-11-07 19:50:23] epoch[4](12000/20000) Loss: 1.0907 Acc@1: 74.55 Acc@5: 90.63 time: 463.1494
[2021-11-07 19:58:07] epoch[4](14000/20000) Loss: 1.0920 Acc@1: 74.53 Acc@5: 90.60 time: 463.2663
[2021-11-07 20:05:51] epoch[4](16000/20000) Loss: 1.0920 Acc@1: 74.52 Acc@5: 90.59 time: 464.1894
[2021-11-07 20:13:37] epoch[4](18000/20000) Loss: 1.0915 Acc@1: 74.54 Acc@5: 90.60 time: 465.9216
[2021-11-07 20:21:22] epoch[4](20000/20000) Loss: 1.0925 Acc@1: 74.52 Acc@5: 90.58 time: 465.6345
[2021-11-07 20:21:27] train    Loss: 1.0926 Acc@1: 74.53 Acc@5: 90.58 time: 4645.9353
[2021-11-07 20:23:18] validate Loss: 0.9919 Acc@1: 75.02 Acc@5: 92.28 time: 111.3194
[2021-11-07 20:23:18] epoch 5 learning_rate 1e-05 
[2021-11-07 20:31:07] epoch[5](2000/20000) Loss: 1.0883 Acc@1: 74.59 Acc@5: 90.56 time: 469.2900
[2021-11-07 20:38:54] epoch[5](4000/20000) Loss: 1.0912 Acc@1: 74.56 Acc@5: 90.57 time: 466.2354
[2021-11-07 20:46:40] epoch[5](6000/20000) Loss: 1.0949 Acc@1: 74.51 Acc@5: 90.51 time: 465.8951
[2021-11-07 20:54:26] epoch[5](8000/20000) Loss: 1.0951 Acc@1: 74.47 Acc@5: 90.51 time: 466.2275
[2021-11-07 21:02:12] epoch[5](10000/20000) Loss: 1.0944 Acc@1: 74.49 Acc@5: 90.53 time: 466.0464
[2021-11-07 21:09:58] epoch[5](12000/20000) Loss: 1.0957 Acc@1: 74.46 Acc@5: 90.51 time: 466.0860
[2021-11-07 21:17:44] epoch[5](14000/20000) Loss: 1.0941 Acc@1: 74.48 Acc@5: 90.55 time: 466.3262
[2021-11-07 21:25:31] epoch[5](16000/20000) Loss: 1.0928 Acc@1: 74.50 Acc@5: 90.57 time: 466.2642
[2021-11-07 21:33:17] epoch[5](18000/20000) Loss: 1.0930 Acc@1: 74.48 Acc@5: 90.56 time: 466.2279
[2021-11-07 21:41:03] epoch[5](20000/20000) Loss: 1.0938 Acc@1: 74.47 Acc@5: 90.55 time: 466.1772
[2021-11-07 21:41:07] train    Loss: 1.0937 Acc@1: 74.47 Acc@5: 90.55 time: 4669.2121
[2021-11-07 21:43:00] validate Loss: 0.9888 Acc@1: 74.95 Acc@5: 92.29 time: 112.6760
[2021-11-07 21:43:00] epoch 6 learning_rate 1e-05 
[2021-11-07 21:50:49] epoch[6](2000/20000) Loss: 1.0903 Acc@1: 74.52 Acc@5: 90.66 time: 469.4703
[2021-11-07 21:58:36] epoch[6](4000/20000) Loss: 1.0923 Acc@1: 74.45 Acc@5: 90.59 time: 466.2684
[2021-11-07 22:06:21] epoch[6](6000/20000) Loss: 1.0905 Acc@1: 74.51 Acc@5: 90.61 time: 465.5977
[2021-11-07 22:14:05] epoch[6](8000/20000) Loss: 1.0905 Acc@1: 74.50 Acc@5: 90.61 time: 463.4952
[2021-11-07 22:21:48] epoch[6](10000/20000) Loss: 1.0918 Acc@1: 74.48 Acc@5: 90.59 time: 463.3595
[2021-11-07 22:29:32] epoch[6](12000/20000) Loss: 1.0912 Acc@1: 74.50 Acc@5: 90.60 time: 463.5220
[2021-11-07 22:37:15] epoch[6](14000/20000) Loss: 1.0915 Acc@1: 74.50 Acc@5: 90.59 time: 463.5110
[2021-11-07 22:44:59] epoch[6](16000/20000) Loss: 1.0916 Acc@1: 74.51 Acc@5: 90.59 time: 463.5333
[2021-11-07 22:52:42] epoch[6](18000/20000) Loss: 1.0913 Acc@1: 74.51 Acc@5: 90.60 time: 463.3592
[2021-11-07 23:00:26] epoch[6](20000/20000) Loss: 1.0913 Acc@1: 74.52 Acc@5: 90.60 time: 463.5507
[2021-11-07 23:00:30] train    Loss: 1.0914 Acc@1: 74.52 Acc@5: 90.60 time: 4649.9564
[2021-11-07 23:01:57] validate Loss: 0.9901 Acc@1: 75.06 Acc@5: 92.25 time: 87.0659
[2021-11-07 23:01:57] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 23:01:57] epoch 7 learning_rate 1e-05 
[2021-11-07 23:09:44] epoch[7](2000/20000) Loss: 1.0921 Acc@1: 74.67 Acc@5: 90.53 time: 466.2270
[2021-11-07 23:17:27] epoch[7](4000/20000) Loss: 1.0921 Acc@1: 74.57 Acc@5: 90.58 time: 463.5210
[2021-11-07 23:25:11] epoch[7](6000/20000) Loss: 1.0933 Acc@1: 74.58 Acc@5: 90.58 time: 463.4408
[2021-11-07 23:32:54] epoch[7](8000/20000) Loss: 1.0927 Acc@1: 74.59 Acc@5: 90.58 time: 463.6060
[2021-11-07 23:40:38] epoch[7](10000/20000) Loss: 1.0924 Acc@1: 74.56 Acc@5: 90.58 time: 463.4658
[2021-11-07 23:48:21] epoch[7](12000/20000) Loss: 1.0925 Acc@1: 74.57 Acc@5: 90.59 time: 463.5105
[2021-11-07 23:56:05] epoch[7](14000/20000) Loss: 1.0922 Acc@1: 74.58 Acc@5: 90.59 time: 463.4123
[2021-11-08 00:03:48] epoch[7](16000/20000) Loss: 1.0923 Acc@1: 74.56 Acc@5: 90.60 time: 463.4507
[2021-11-08 00:11:32] epoch[7](18000/20000) Loss: 1.0933 Acc@1: 74.53 Acc@5: 90.58 time: 463.5630
[2021-11-08 00:19:15] epoch[7](20000/20000) Loss: 1.0937 Acc@1: 74.52 Acc@5: 90.58 time: 463.6657
[2021-11-08 00:19:20] train    Loss: 1.0936 Acc@1: 74.52 Acc@5: 90.58 time: 4642.1816
[2021-11-08 00:20:47] validate Loss: 0.9922 Acc@1: 75.08 Acc@5: 92.28 time: 87.6186
[2021-11-08 00:20:47] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-08 00:20:47] epoch 8 learning_rate 1e-05 
[2021-11-08 00:28:34] epoch[8](2000/20000) Loss: 1.0911 Acc@1: 74.52 Acc@5: 90.68 time: 466.3438
[2021-11-08 00:36:17] epoch[8](4000/20000) Loss: 1.0945 Acc@1: 74.47 Acc@5: 90.60 time: 463.4005
[2021-11-08 00:44:01] epoch[8](6000/20000) Loss: 1.0929 Acc@1: 74.53 Acc@5: 90.64 time: 463.4650
[2021-11-08 00:51:44] epoch[8](8000/20000) Loss: 1.0930 Acc@1: 74.53 Acc@5: 90.63 time: 463.2814
[2021-11-08 00:59:27] epoch[8](10000/20000) Loss: 1.0919 Acc@1: 74.53 Acc@5: 90.64 time: 463.4450
[2021-11-08 01:07:11] epoch[8](12000/20000) Loss: 1.0910 Acc@1: 74.52 Acc@5: 90.65 time: 463.4166
[2021-11-08 01:14:54] epoch[8](14000/20000) Loss: 1.0913 Acc@1: 74.55 Acc@5: 90.65 time: 463.5379
[2021-11-08 01:22:38] epoch[8](16000/20000) Loss: 1.0906 Acc@1: 74.56 Acc@5: 90.65 time: 463.5418
[2021-11-08 01:30:21] epoch[8](18000/20000) Loss: 1.0904 Acc@1: 74.57 Acc@5: 90.64 time: 463.4286
[2021-11-08 01:38:05] epoch[8](20000/20000) Loss: 1.0911 Acc@1: 74.54 Acc@5: 90.63 time: 463.2943
[2021-11-08 01:38:09] train    Loss: 1.0911 Acc@1: 74.54 Acc@5: 90.63 time: 4641.4843
[2021-11-08 01:39:41] validate Loss: 0.9896 Acc@1: 74.99 Acc@5: 92.29 time: 91.8285
[2021-11-08 01:39:41] epoch 9 learning_rate 1e-05 
[2021-11-08 01:47:27] epoch[9](2000/20000) Loss: 1.0832 Acc@1: 74.70 Acc@5: 90.72 time: 466.2450
[2021-11-08 01:55:10] epoch[9](4000/20000) Loss: 1.0860 Acc@1: 74.68 Acc@5: 90.70 time: 463.3471
[2021-11-08 02:02:54] epoch[9](6000/20000) Loss: 1.0875 Acc@1: 74.65 Acc@5: 90.68 time: 463.2438
[2021-11-08 02:10:37] epoch[9](8000/20000) Loss: 1.0870 Acc@1: 74.64 Acc@5: 90.67 time: 463.1535
[2021-11-08 02:18:20] epoch[9](10000/20000) Loss: 1.0889 Acc@1: 74.60 Acc@5: 90.65 time: 463.2768
[2021-11-08 02:26:03] epoch[9](12000/20000) Loss: 1.0901 Acc@1: 74.59 Acc@5: 90.62 time: 463.2588
[2021-11-08 02:33:47] epoch[9](14000/20000) Loss: 1.0895 Acc@1: 74.60 Acc@5: 90.64 time: 463.3959
[2021-11-08 02:41:30] epoch[9](16000/20000) Loss: 1.0890 Acc@1: 74.61 Acc@5: 90.65 time: 463.5309
[2021-11-08 02:49:13] epoch[9](18000/20000) Loss: 1.0901 Acc@1: 74.59 Acc@5: 90.62 time: 463.1079
[2021-11-08 02:56:57] epoch[9](20000/20000) Loss: 1.0904 Acc@1: 74.59 Acc@5: 90.61 time: 463.2198
[2021-11-08 02:57:01] train    Loss: 1.0904 Acc@1: 74.58 Acc@5: 90.61 time: 4640.1177
[2021-11-08 02:58:32] validate Loss: 0.9897 Acc@1: 74.96 Acc@5: 92.27 time: 91.0597
[2021-11-08 02:58:33] storing pruned_model:/finally_pruned_model/resnet_50_22_fs.pt
[2021-11-08 02:59:54] validate Loss: 0.9922 Acc@1: 75.08 Acc@5: 92.28 time: 81.3514
[2021-11-08 02:59:54] finally model  Acc@1: 75.08 Acc@5: 92.28 flops: 2134021533.0 params:16082147.0
