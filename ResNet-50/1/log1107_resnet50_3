[2021-11-06 17:42:01] args:Namespace(ablation_id=0, arch='resnet_50', batch_size=64, compress_rate=None, data_dir='/home/featurize/data', dataset='ImageNet', epochs=15, from_scratch=True, gpu=0, input_size=224, job_dir='/home/featurize/work/CCCrank5', lr=0.0001, lr_decay_step='5', momentum=0.9, num_workers=8, pretrained=False, resume='finally_pruned_model/resnet_50_1106_11_fs.pt', save_id=22, start_cov=-1, weight_decay=0.0005)
[2021-11-06 17:42:02] loading checkpoint:finally_pruned_model/resnet_50_1106_11_fs.pt
[2021-11-06 17:43:25] validate Loss: 0.9985 Acc@1: 74.81 Acc@5: 92.25 time: 83.4974
[2021-11-06 17:43:25] epoch 0 learning_rate 0.0001 
[2021-11-06 17:51:14] epoch[0](2000/20000) Loss: 1.1308 Acc@1: 73.68 Acc@5: 90.09 time: 468.9110
[2021-11-06 17:59:00] epoch[0](4000/20000) Loss: 1.1320 Acc@1: 73.63 Acc@5: 90.11 time: 465.7986
[2021-11-06 18:06:46] epoch[0](6000/20000) Loss: 1.1345 Acc@1: 73.60 Acc@5: 90.07 time: 465.8105
[2021-11-06 18:14:31] epoch[0](8000/20000) Loss: 1.1387 Acc@1: 73.50 Acc@5: 90.02 time: 465.7016
[2021-11-06 18:22:17] epoch[0](10000/20000) Loss: 1.1397 Acc@1: 73.49 Acc@5: 90.01 time: 465.8210
[2021-11-06 18:30:03] epoch[0](12000/20000) Loss: 1.1405 Acc@1: 73.43 Acc@5: 90.00 time: 465.6465
[2021-11-06 18:37:49] epoch[0](14000/20000) Loss: 1.1427 Acc@1: 73.40 Acc@5: 89.98 time: 465.7219
[2021-11-06 18:45:34] epoch[0](16000/20000) Loss: 1.1435 Acc@1: 73.39 Acc@5: 89.97 time: 465.7902
[2021-11-06 18:53:20] epoch[0](18000/20000) Loss: 1.1447 Acc@1: 73.35 Acc@5: 89.95 time: 466.0174
[2021-11-06 19:01:06] epoch[0](20000/20000) Loss: 1.1460 Acc@1: 73.31 Acc@5: 89.94 time: 465.7885
[2021-11-06 19:01:11] train    Loss: 1.1461 Acc@1: 73.31 Acc@5: 89.94 time: 4665.3690
[2021-11-06 19:02:42] validate Loss: 1.0162 Acc@1: 74.40 Acc@5: 92.12 time: 91.5441
[2021-11-06 19:02:42] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-06 19:02:42] epoch 1 learning_rate 0.0001 
[2021-11-06 19:10:31] epoch[1](2000/20000) Loss: 1.1448 Acc@1: 73.28 Acc@5: 90.06 time: 468.7004
[2021-11-06 19:18:17] epoch[1](4000/20000) Loss: 1.1379 Acc@1: 73.45 Acc@5: 90.11 time: 465.7842
[2021-11-06 19:26:03] epoch[1](6000/20000) Loss: 1.1403 Acc@1: 73.42 Acc@5: 90.07 time: 465.9821
[2021-11-06 19:33:49] epoch[1](8000/20000) Loss: 1.1419 Acc@1: 73.39 Acc@5: 90.04 time: 465.8737
[2021-11-06 19:41:35] epoch[1](10000/20000) Loss: 1.1417 Acc@1: 73.38 Acc@5: 90.03 time: 465.8925
[2021-11-06 19:49:20] epoch[1](12000/20000) Loss: 1.1441 Acc@1: 73.33 Acc@5: 89.99 time: 465.8040
[2021-11-06 19:57:06] epoch[1](14000/20000) Loss: 1.1440 Acc@1: 73.32 Acc@5: 89.99 time: 465.9847
[2021-11-06 20:04:52] epoch[1](16000/20000) Loss: 1.1454 Acc@1: 73.30 Acc@5: 89.98 time: 465.9059
[2021-11-06 20:12:38] epoch[1](18000/20000) Loss: 1.1457 Acc@1: 73.28 Acc@5: 89.98 time: 465.9100
[2021-11-06 20:20:24] epoch[1](20000/20000) Loss: 1.1472 Acc@1: 73.24 Acc@5: 89.96 time: 465.9616
[2021-11-06 20:20:29] train    Loss: 1.1471 Acc@1: 73.24 Acc@5: 89.96 time: 4666.1384
[2021-11-06 20:22:03] validate Loss: 1.0143 Acc@1: 74.55 Acc@5: 92.08 time: 94.1094
[2021-11-06 20:22:03] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-06 20:22:03] epoch 2 learning_rate 0.0001 
[2021-11-06 20:29:52] epoch[2](2000/20000) Loss: 1.1370 Acc@1: 73.68 Acc@5: 90.02 time: 469.0040
[2021-11-06 20:37:38] epoch[2](4000/20000) Loss: 1.1400 Acc@1: 73.49 Acc@5: 90.04 time: 465.8901
[2021-11-06 20:45:24] epoch[2](6000/20000) Loss: 1.1424 Acc@1: 73.42 Acc@5: 89.99 time: 465.7852
[2021-11-06 20:53:09] epoch[2](8000/20000) Loss: 1.1425 Acc@1: 73.39 Acc@5: 89.97 time: 465.7121
[2021-11-06 21:00:55] epoch[2](10000/20000) Loss: 1.1410 Acc@1: 73.41 Acc@5: 89.99 time: 465.7127
[2021-11-06 21:08:41] epoch[2](12000/20000) Loss: 1.1423 Acc@1: 73.38 Acc@5: 89.99 time: 465.6896
[2021-11-06 21:16:26] epoch[2](14000/20000) Loss: 1.1425 Acc@1: 73.39 Acc@5: 90.00 time: 465.7295
[2021-11-06 21:24:12] epoch[2](16000/20000) Loss: 1.1426 Acc@1: 73.38 Acc@5: 90.00 time: 465.7364
[2021-11-06 21:31:58] epoch[2](18000/20000) Loss: 1.1444 Acc@1: 73.34 Acc@5: 89.98 time: 465.6964
[2021-11-06 21:39:44] epoch[2](20000/20000) Loss: 1.1456 Acc@1: 73.30 Acc@5: 89.96 time: 465.7215
[2021-11-06 21:39:48] train    Loss: 1.1455 Acc@1: 73.30 Acc@5: 89.96 time: 4664.9924
[2021-11-06 21:41:20] validate Loss: 1.0163 Acc@1: 74.38 Acc@5: 92.07 time: 91.6670
[2021-11-06 21:41:20] epoch 3 learning_rate 0.0001 
[2021-11-06 21:49:08] epoch[3](2000/20000) Loss: 1.1361 Acc@1: 73.60 Acc@5: 90.07 time: 468.7982
[2021-11-06 21:56:54] epoch[3](4000/20000) Loss: 1.1373 Acc@1: 73.58 Acc@5: 90.05 time: 465.7702
[2021-11-06 22:04:40] epoch[3](6000/20000) Loss: 1.1387 Acc@1: 73.50 Acc@5: 90.02 time: 465.8299
[2021-11-06 22:12:26] epoch[3](8000/20000) Loss: 1.1401 Acc@1: 73.47 Acc@5: 90.01 time: 465.6808
[2021-11-06 22:20:11] epoch[3](10000/20000) Loss: 1.1424 Acc@1: 73.41 Acc@5: 89.99 time: 465.7051
[2021-11-06 22:27:57] epoch[3](12000/20000) Loss: 1.1441 Acc@1: 73.38 Acc@5: 89.95 time: 465.6941
[2021-11-06 22:35:43] epoch[3](14000/20000) Loss: 1.1442 Acc@1: 73.38 Acc@5: 89.95 time: 465.6907
[2021-11-06 22:43:28] epoch[3](16000/20000) Loss: 1.1449 Acc@1: 73.36 Acc@5: 89.95 time: 465.7319
[2021-11-06 22:51:14] epoch[3](18000/20000) Loss: 1.1460 Acc@1: 73.32 Acc@5: 89.94 time: 465.5572
[2021-11-06 22:59:00] epoch[3](20000/20000) Loss: 1.1462 Acc@1: 73.32 Acc@5: 89.94 time: 465.6161
[2021-11-06 22:59:04] train    Loss: 1.1462 Acc@1: 73.32 Acc@5: 89.94 time: 4664.4676
[2021-11-06 23:00:35] validate Loss: 1.0174 Acc@1: 74.26 Acc@5: 92.04 time: 90.9663
[2021-11-06 23:00:35] epoch 4 learning_rate 0.0001 
[2021-11-06 23:08:24] epoch[4](2000/20000) Loss: 1.1370 Acc@1: 73.43 Acc@5: 90.05 time: 468.9183
[2021-11-06 23:16:10] epoch[4](4000/20000) Loss: 1.1380 Acc@1: 73.51 Acc@5: 89.99 time: 465.6490
[2021-11-06 23:23:55] epoch[4](6000/20000) Loss: 1.1389 Acc@1: 73.47 Acc@5: 90.01 time: 465.7586
[2021-11-06 23:31:41] epoch[4](8000/20000) Loss: 1.1400 Acc@1: 73.42 Acc@5: 89.98 time: 465.8240
[2021-11-06 23:39:27] epoch[4](10000/20000) Loss: 1.1418 Acc@1: 73.38 Acc@5: 89.98 time: 465.6172
[2021-11-06 23:47:12] epoch[4](12000/20000) Loss: 1.1435 Acc@1: 73.32 Acc@5: 89.97 time: 465.7304
[2021-11-06 23:54:58] epoch[4](14000/20000) Loss: 1.1442 Acc@1: 73.31 Acc@5: 89.97 time: 465.6032
[2021-11-07 00:02:44] epoch[4](16000/20000) Loss: 1.1443 Acc@1: 73.30 Acc@5: 89.97 time: 465.8325
[2021-11-07 00:10:30] epoch[4](18000/20000) Loss: 1.1454 Acc@1: 73.28 Acc@5: 89.95 time: 465.7649
[2021-11-07 00:18:15] epoch[4](20000/20000) Loss: 1.1459 Acc@1: 73.26 Acc@5: 89.94 time: 465.7486
[2021-11-07 00:18:20] train    Loss: 1.1459 Acc@1: 73.26 Acc@5: 89.94 time: 4664.7731
[2021-11-07 00:19:52] validate Loss: 1.0151 Acc@1: 74.51 Acc@5: 91.97 time: 92.1798
[2021-11-07 00:19:52] epoch 5 learning_rate 1e-05 
[2021-11-07 00:27:41] epoch[5](2000/20000) Loss: 1.1175 Acc@1: 73.84 Acc@5: 90.33 time: 468.8097
[2021-11-07 00:35:26] epoch[5](4000/20000) Loss: 1.1249 Acc@1: 73.77 Acc@5: 90.21 time: 465.6629
[2021-11-07 00:43:12] epoch[5](6000/20000) Loss: 1.1224 Acc@1: 73.83 Acc@5: 90.24 time: 465.6161
[2021-11-07 00:50:58] epoch[5](8000/20000) Loss: 1.1196 Acc@1: 73.88 Acc@5: 90.29 time: 465.6523
[2021-11-07 00:58:44] epoch[5](10000/20000) Loss: 1.1193 Acc@1: 73.89 Acc@5: 90.27 time: 465.8653
[2021-11-07 01:06:29] epoch[5](12000/20000) Loss: 1.1195 Acc@1: 73.89 Acc@5: 90.25 time: 465.6764
[2021-11-07 01:14:15] epoch[5](14000/20000) Loss: 1.1184 Acc@1: 73.91 Acc@5: 90.27 time: 465.8261
[2021-11-07 01:22:01] epoch[5](16000/20000) Loss: 1.1170 Acc@1: 73.96 Acc@5: 90.28 time: 465.7421
[2021-11-07 01:29:47] epoch[5](18000/20000) Loss: 1.1156 Acc@1: 73.98 Acc@5: 90.32 time: 465.8380
[2021-11-07 01:37:32] epoch[5](20000/20000) Loss: 1.1154 Acc@1: 73.98 Acc@5: 90.32 time: 465.7508
[2021-11-07 01:37:37] train    Loss: 1.1154 Acc@1: 73.98 Acc@5: 90.32 time: 4664.7804
[2021-11-07 01:39:08] validate Loss: 0.9991 Acc@1: 74.74 Acc@5: 92.15 time: 91.2777
[2021-11-07 01:39:08] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 01:39:08] epoch 6 learning_rate 1e-05 
[2021-11-07 01:46:57] epoch[6](2000/20000) Loss: 1.1001 Acc@1: 74.31 Acc@5: 90.52 time: 468.6744
[2021-11-07 01:54:43] epoch[6](4000/20000) Loss: 1.1063 Acc@1: 74.22 Acc@5: 90.45 time: 465.8455
[2021-11-07 02:02:28] epoch[6](6000/20000) Loss: 1.1053 Acc@1: 74.25 Acc@5: 90.45 time: 465.6469
[2021-11-07 02:10:14] epoch[6](8000/20000) Loss: 1.1044 Acc@1: 74.25 Acc@5: 90.46 time: 465.6504
[2021-11-07 02:18:00] epoch[6](10000/20000) Loss: 1.1041 Acc@1: 74.25 Acc@5: 90.46 time: 465.7232
[2021-11-07 02:25:46] epoch[6](12000/20000) Loss: 1.1053 Acc@1: 74.23 Acc@5: 90.44 time: 465.7450
[2021-11-07 02:33:31] epoch[6](14000/20000) Loss: 1.1058 Acc@1: 74.21 Acc@5: 90.42 time: 465.8268
[2021-11-07 02:41:17] epoch[6](16000/20000) Loss: 1.1065 Acc@1: 74.19 Acc@5: 90.42 time: 465.6151
[2021-11-07 02:49:03] epoch[6](18000/20000) Loss: 1.1064 Acc@1: 74.20 Acc@5: 90.41 time: 465.8027
[2021-11-07 02:56:48] epoch[6](20000/20000) Loss: 1.1066 Acc@1: 74.20 Acc@5: 90.41 time: 465.6681
[2021-11-07 02:56:53] train    Loss: 1.1066 Acc@1: 74.20 Acc@5: 90.41 time: 4664.5414
[2021-11-07 02:58:24] validate Loss: 0.9994 Acc@1: 74.79 Acc@5: 92.23 time: 91.3754
[2021-11-07 02:58:24] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 02:58:24] epoch 7 learning_rate 1e-05 
[2021-11-07 03:06:13] epoch[7](2000/20000) Loss: 1.1028 Acc@1: 74.33 Acc@5: 90.47 time: 468.8446
[2021-11-07 03:13:59] epoch[7](4000/20000) Loss: 1.1026 Acc@1: 74.34 Acc@5: 90.45 time: 465.6014
[2021-11-07 03:21:45] epoch[7](6000/20000) Loss: 1.1037 Acc@1: 74.37 Acc@5: 90.43 time: 465.8019
[2021-11-07 03:29:30] epoch[7](8000/20000) Loss: 1.1039 Acc@1: 74.34 Acc@5: 90.43 time: 465.7259
[2021-11-07 03:37:16] epoch[7](10000/20000) Loss: 1.1044 Acc@1: 74.30 Acc@5: 90.43 time: 465.7407
[2021-11-07 03:45:02] epoch[7](12000/20000) Loss: 1.1039 Acc@1: 74.31 Acc@5: 90.44 time: 465.8814
[2021-11-07 03:52:48] epoch[7](14000/20000) Loss: 1.1043 Acc@1: 74.28 Acc@5: 90.41 time: 465.7891
[2021-11-07 04:00:33] epoch[7](16000/20000) Loss: 1.1037 Acc@1: 74.29 Acc@5: 90.43 time: 465.6309
[2021-11-07 04:08:19] epoch[7](18000/20000) Loss: 1.1037 Acc@1: 74.28 Acc@5: 90.45 time: 465.6344
[2021-11-07 04:16:05] epoch[7](20000/20000) Loss: 1.1031 Acc@1: 74.29 Acc@5: 90.45 time: 465.5754
[2021-11-07 04:16:09] train    Loss: 1.1032 Acc@1: 74.29 Acc@5: 90.45 time: 4664.5691
[2021-11-07 04:17:40] validate Loss: 1.0003 Acc@1: 74.84 Acc@5: 92.22 time: 90.7336
[2021-11-07 04:17:40] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 04:17:40] epoch 8 learning_rate 1e-05 
[2021-11-07 04:25:29] epoch[8](2000/20000) Loss: 1.1037 Acc@1: 74.32 Acc@5: 90.46 time: 468.6416
[2021-11-07 04:33:14] epoch[8](4000/20000) Loss: 1.1023 Acc@1: 74.33 Acc@5: 90.46 time: 465.7795
[2021-11-07 04:41:00] epoch[8](6000/20000) Loss: 1.1022 Acc@1: 74.32 Acc@5: 90.48 time: 465.6277
[2021-11-07 04:48:46] epoch[8](8000/20000) Loss: 1.1032 Acc@1: 74.27 Acc@5: 90.47 time: 465.7394
[2021-11-07 04:56:32] epoch[8](10000/20000) Loss: 1.1020 Acc@1: 74.33 Acc@5: 90.46 time: 465.7472
[2021-11-07 05:04:17] epoch[8](12000/20000) Loss: 1.1025 Acc@1: 74.32 Acc@5: 90.45 time: 465.6224
[2021-11-07 05:12:03] epoch[8](14000/20000) Loss: 1.1038 Acc@1: 74.29 Acc@5: 90.42 time: 465.7378
[2021-11-07 05:19:49] epoch[8](16000/20000) Loss: 1.1036 Acc@1: 74.28 Acc@5: 90.43 time: 465.6970
[2021-11-07 05:27:34] epoch[8](18000/20000) Loss: 1.1028 Acc@1: 74.30 Acc@5: 90.44 time: 465.7926
[2021-11-07 05:35:20] epoch[8](20000/20000) Loss: 1.1030 Acc@1: 74.30 Acc@5: 90.44 time: 465.6431
[2021-11-07 05:35:24] train    Loss: 1.1030 Acc@1: 74.30 Acc@5: 90.44 time: 4664.3552
[2021-11-07 05:36:56] validate Loss: 0.9977 Acc@1: 74.80 Acc@5: 92.24 time: 91.3669
[2021-11-07 05:36:56] epoch 9 learning_rate 1e-05 
[2021-11-07 05:44:44] epoch[9](2000/20000) Loss: 1.1009 Acc@1: 74.33 Acc@5: 90.57 time: 468.7589
[2021-11-07 05:52:30] epoch[9](4000/20000) Loss: 1.1011 Acc@1: 74.29 Acc@5: 90.50 time: 465.6923
[2021-11-07 06:00:16] epoch[9](6000/20000) Loss: 1.1021 Acc@1: 74.30 Acc@5: 90.46 time: 465.5868
[2021-11-07 06:08:01] epoch[9](8000/20000) Loss: 1.1003 Acc@1: 74.32 Acc@5: 90.50 time: 465.6846
[2021-11-07 06:15:47] epoch[9](10000/20000) Loss: 1.1000 Acc@1: 74.33 Acc@5: 90.50 time: 465.7714
[2021-11-07 06:23:33] epoch[9](12000/20000) Loss: 1.0989 Acc@1: 74.37 Acc@5: 90.51 time: 465.6298
[2021-11-07 06:31:19] epoch[9](14000/20000) Loss: 1.0987 Acc@1: 74.36 Acc@5: 90.52 time: 465.6915
[2021-11-07 06:39:04] epoch[9](16000/20000) Loss: 1.0974 Acc@1: 74.39 Acc@5: 90.52 time: 465.8002
[2021-11-07 06:46:50] epoch[9](18000/20000) Loss: 1.0988 Acc@1: 74.36 Acc@5: 90.51 time: 465.7087
[2021-11-07 06:54:36] epoch[9](20000/20000) Loss: 1.0993 Acc@1: 74.35 Acc@5: 90.51 time: 465.7587
[2021-11-07 06:54:40] train    Loss: 1.0993 Acc@1: 74.35 Acc@5: 90.51 time: 4664.3723
[2021-11-07 06:56:06] validate Loss: 0.9957 Acc@1: 74.86 Acc@5: 92.19 time: 86.0493
[2021-11-07 06:56:06] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 06:56:06] epoch 10 learning_rate 1e-05 
[2021-11-07 07:03:55] epoch[10](2000/20000) Loss: 1.0965 Acc@1: 74.44 Acc@5: 90.55 time: 468.4504
[2021-11-07 07:11:40] epoch[10](4000/20000) Loss: 1.0946 Acc@1: 74.48 Acc@5: 90.57 time: 465.6674
[2021-11-07 07:19:26] epoch[10](6000/20000) Loss: 1.0948 Acc@1: 74.46 Acc@5: 90.55 time: 465.6850
[2021-11-07 07:27:12] epoch[10](8000/20000) Loss: 1.0973 Acc@1: 74.39 Acc@5: 90.55 time: 465.8649
[2021-11-07 07:34:58] epoch[10](10000/20000) Loss: 1.0976 Acc@1: 74.37 Acc@5: 90.53 time: 465.9843
[2021-11-07 07:42:44] epoch[10](12000/20000) Loss: 1.0981 Acc@1: 74.37 Acc@5: 90.54 time: 465.8086
[2021-11-07 07:50:30] epoch[10](14000/20000) Loss: 1.0981 Acc@1: 74.36 Acc@5: 90.53 time: 465.8712
[2021-11-07 07:58:15] epoch[10](16000/20000) Loss: 1.0988 Acc@1: 74.34 Acc@5: 90.52 time: 465.6310
[2021-11-07 08:06:01] epoch[10](18000/20000) Loss: 1.0995 Acc@1: 74.33 Acc@5: 90.50 time: 465.7121
[2021-11-07 08:13:47] epoch[10](20000/20000) Loss: 1.0999 Acc@1: 74.34 Acc@5: 90.50 time: 465.8910
[2021-11-07 08:13:51] train    Loss: 1.0998 Acc@1: 74.34 Acc@5: 90.50 time: 4664.8639
[2021-11-07 08:15:17] validate Loss: 0.9932 Acc@1: 74.96 Acc@5: 92.33 time: 86.2817
[2021-11-07 08:15:18] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 08:15:18] epoch 11 learning_rate 1e-05 
[2021-11-07 08:23:06] epoch[11](2000/20000) Loss: 1.0993 Acc@1: 74.33 Acc@5: 90.52 time: 468.5962
[2021-11-07 08:30:52] epoch[11](4000/20000) Loss: 1.0984 Acc@1: 74.41 Acc@5: 90.52 time: 465.7597
[2021-11-07 08:38:38] epoch[11](6000/20000) Loss: 1.0984 Acc@1: 74.44 Acc@5: 90.53 time: 465.8065
[2021-11-07 08:46:24] epoch[11](8000/20000) Loss: 1.0982 Acc@1: 74.43 Acc@5: 90.53 time: 465.7919
[2021-11-07 08:54:10] epoch[11](10000/20000) Loss: 1.0974 Acc@1: 74.43 Acc@5: 90.53 time: 465.8337
[2021-11-07 09:01:55] epoch[11](12000/20000) Loss: 1.0967 Acc@1: 74.45 Acc@5: 90.54 time: 465.9385
[2021-11-07 09:09:41] epoch[11](14000/20000) Loss: 1.0969 Acc@1: 74.44 Acc@5: 90.54 time: 465.6525
[2021-11-07 09:17:27] epoch[11](16000/20000) Loss: 1.0969 Acc@1: 74.42 Acc@5: 90.54 time: 465.8263
[2021-11-07 09:25:13] epoch[11](18000/20000) Loss: 1.0975 Acc@1: 74.41 Acc@5: 90.52 time: 465.7292
[2021-11-07 09:32:58] epoch[11](20000/20000) Loss: 1.0974 Acc@1: 74.41 Acc@5: 90.52 time: 465.5676
[2021-11-07 09:33:03] train    Loss: 1.0974 Acc@1: 74.41 Acc@5: 90.52 time: 4664.8271
[2021-11-07 09:34:33] validate Loss: 0.9938 Acc@1: 74.91 Acc@5: 92.28 time: 90.9030
[2021-11-07 09:34:33] epoch 12 learning_rate 1e-05 
[2021-11-07 09:42:22] epoch[12](2000/20000) Loss: 1.0952 Acc@1: 74.48 Acc@5: 90.55 time: 468.6847
[2021-11-07 09:50:08] epoch[12](4000/20000) Loss: 1.0964 Acc@1: 74.42 Acc@5: 90.56 time: 465.5107
[2021-11-07 09:57:53] epoch[12](6000/20000) Loss: 1.0965 Acc@1: 74.44 Acc@5: 90.55 time: 465.7301
[2021-11-07 10:05:39] epoch[12](8000/20000) Loss: 1.0969 Acc@1: 74.40 Acc@5: 90.54 time: 465.6368
[2021-11-07 10:13:25] epoch[12](10000/20000) Loss: 1.0968 Acc@1: 74.38 Acc@5: 90.55 time: 465.5563
[2021-11-07 10:21:10] epoch[12](12000/20000) Loss: 1.0980 Acc@1: 74.36 Acc@5: 90.53 time: 465.7077
[2021-11-07 10:28:56] epoch[12](14000/20000) Loss: 1.0985 Acc@1: 74.39 Acc@5: 90.51 time: 465.7479
[2021-11-07 10:36:42] epoch[12](16000/20000) Loss: 1.0984 Acc@1: 74.40 Acc@5: 90.51 time: 465.7769
[2021-11-07 10:44:28] epoch[12](18000/20000) Loss: 1.0980 Acc@1: 74.39 Acc@5: 90.52 time: 465.7800
[2021-11-07 10:52:13] epoch[12](20000/20000) Loss: 1.0983 Acc@1: 74.38 Acc@5: 90.52 time: 465.6541
[2021-11-07 10:52:18] train    Loss: 1.0983 Acc@1: 74.37 Acc@5: 90.52 time: 4664.0969
[2021-11-07 10:53:49] validate Loss: 0.9904 Acc@1: 75.03 Acc@5: 92.30 time: 90.9752
[2021-11-07 10:53:49] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-07 10:53:49] epoch 13 learning_rate 1e-05 
[2021-11-07 11:01:38] epoch[13](2000/20000) Loss: 1.0958 Acc@1: 74.50 Acc@5: 90.43 time: 468.6985
[2021-11-07 11:09:24] epoch[13](4000/20000) Loss: 1.0949 Acc@1: 74.46 Acc@5: 90.53 time: 465.8876
[2021-11-07 11:17:09] epoch[13](6000/20000) Loss: 1.0992 Acc@1: 74.37 Acc@5: 90.44 time: 465.7435
[2021-11-07 11:24:55] epoch[13](8000/20000) Loss: 1.1001 Acc@1: 74.35 Acc@5: 90.48 time: 465.5048
[2021-11-07 11:32:40] epoch[13](10000/20000) Loss: 1.0985 Acc@1: 74.39 Acc@5: 90.50 time: 465.5095
[2021-11-07 11:40:26] epoch[13](12000/20000) Loss: 1.0984 Acc@1: 74.39 Acc@5: 90.51 time: 465.6612
[2021-11-07 11:48:12] epoch[13](14000/20000) Loss: 1.0976 Acc@1: 74.42 Acc@5: 90.52 time: 465.6742
[2021-11-07 11:55:57] epoch[13](16000/20000) Loss: 1.0975 Acc@1: 74.43 Acc@5: 90.53 time: 465.7443
[2021-11-07 12:03:43] epoch[13](18000/20000) Loss: 1.0977 Acc@1: 74.42 Acc@5: 90.53 time: 465.4748
[2021-11-07 12:11:29] epoch[13](20000/20000) Loss: 1.0975 Acc@1: 74.43 Acc@5: 90.52 time: 465.8114
[2021-11-07 12:11:33] train    Loss: 1.0975 Acc@1: 74.43 Acc@5: 90.52 time: 4664.0541
[2021-11-07 12:13:04] validate Loss: 0.9922 Acc@1: 74.98 Acc@5: 92.33 time: 90.5537
[2021-11-07 12:13:04] epoch 14 learning_rate 1e-05 
[2021-11-07 12:20:52] epoch[14](2000/20000) Loss: 1.0946 Acc@1: 74.43 Acc@5: 90.51 time: 468.8599
[2021-11-07 12:28:38] epoch[14](4000/20000) Loss: 1.0941 Acc@1: 74.48 Acc@5: 90.56 time: 465.8200
[2021-11-07 12:36:24] epoch[14](6000/20000) Loss: 1.0918 Acc@1: 74.52 Acc@5: 90.61 time: 465.6183
[2021-11-07 12:44:10] epoch[14](8000/20000) Loss: 1.0908 Acc@1: 74.54 Acc@5: 90.62 time: 465.6985
[2021-11-07 12:51:55] epoch[14](10000/20000) Loss: 1.0908 Acc@1: 74.56 Acc@5: 90.64 time: 465.5694
[2021-11-07 12:59:41] epoch[14](12000/20000) Loss: 1.0925 Acc@1: 74.53 Acc@5: 90.61 time: 465.6705
[2021-11-07 13:07:27] epoch[14](14000/20000) Loss: 1.0927 Acc@1: 74.52 Acc@5: 90.60 time: 465.8548
[2021-11-07 13:15:12] epoch[14](16000/20000) Loss: 1.0925 Acc@1: 74.52 Acc@5: 90.60 time: 465.7433
[2021-11-07 13:22:58] epoch[14](18000/20000) Loss: 1.0925 Acc@1: 74.51 Acc@5: 90.59 time: 465.8244
[2021-11-07 13:30:44] epoch[14](20000/20000) Loss: 1.0930 Acc@1: 74.50 Acc@5: 90.58 time: 465.7030
[2021-11-07 13:30:48] train    Loss: 1.0930 Acc@1: 74.50 Acc@5: 90.58 time: 4664.6903
[2021-11-07 13:32:20] validate Loss: 0.9931 Acc@1: 75.01 Acc@5: 92.31 time: 91.3758
[2021-11-07 13:32:21] storing pruned_model:/finally_pruned_model/resnet_50_22_fs.pt
[2021-11-07 13:33:42] validate Loss: 0.9904 Acc@1: 75.03 Acc@5: 92.30 time: 81.3695
[2021-11-07 13:33:42] finally model  Acc@1: 75.03 Acc@5: 92.30 flops: 2134021533.0 params:16082147.0
