[2021-11-11 13:35:25] args:Namespace(ablation_id=0, arch='resnet_50', batch_size=64, compress_rate=None, data_dir='G:\\ImageNet', dataset='ImageNet', epochs=30, from_scratch=True, gpu=0, input_size=224, job_dir='C:\\Users\\huxf\\Desktop\\dyztmp\\CCCrank2', lr=0.001, lr_decay_step='5,20', momentum=0.9, num_workers=4, pretrained=False, resume='finally_pruned_model/resnet_50_1111_1.pt', save_id=1, start_cov=-1, weight_decay=0.0005)
[2021-11-11 13:35:25] loading checkpoint:finally_pruned_model/resnet_50_1111_1.pt
[2021-11-11 13:36:41] validate Loss: 1.3187 Acc@1: 67.50 Acc@5: 88.20 time: 76.0855
[2021-11-11 13:36:41] epoch 0 learning_rate 0.001 
[2021-11-11 13:41:56] epoch[0](2000/20000) Loss: 1.7035 Acc@1: 60.65 Acc@5: 82.35 time: 314.6687
[2021-11-11 13:47:01] epoch[0](4000/20000) Loss: 1.7217 Acc@1: 60.33 Acc@5: 82.10 time: 304.9999
[2021-11-11 13:52:06] epoch[0](6000/20000) Loss: 1.7334 Acc@1: 60.15 Acc@5: 81.90 time: 305.2195
[2021-11-11 13:57:11] epoch[0](8000/20000) Loss: 1.7381 Acc@1: 60.07 Acc@5: 81.80 time: 304.9239
[2021-11-11 14:02:17] epoch[0](10000/20000) Loss: 1.7440 Acc@1: 59.98 Acc@5: 81.72 time: 305.3039
[2021-11-11 14:07:21] epoch[0](12000/20000) Loss: 1.7493 Acc@1: 59.89 Acc@5: 81.70 time: 304.7801
[2021-11-11 14:12:26] epoch[0](14000/20000) Loss: 1.7520 Acc@1: 59.85 Acc@5: 81.64 time: 304.9878
[2021-11-11 14:17:32] epoch[0](16000/20000) Loss: 1.7549 Acc@1: 59.80 Acc@5: 81.60 time: 305.1778
[2021-11-11 14:22:37] epoch[0](18000/20000) Loss: 1.7572 Acc@1: 59.77 Acc@5: 81.58 time: 305.0645
[2021-11-11 14:27:42] epoch[0](20000/20000) Loss: 1.7585 Acc@1: 59.73 Acc@5: 81.57 time: 305.8057
[2021-11-11 14:27:46] train    Loss: 1.7585 Acc@1: 59.73 Acc@5: 81.57 time: 3064.0655
[2021-11-11 14:29:03] validate Loss: 1.4195 Acc@1: 65.45 Acc@5: 86.88 time: 77.7595
[2021-11-11 14:29:03] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-11 14:29:03] epoch 1 learning_rate 0.001 
[2021-11-11 14:34:15] epoch[1](2000/20000) Loss: 1.7470 Acc@1: 60.10 Acc@5: 81.76 time: 311.2296
[2021-11-11 14:39:20] epoch[1](4000/20000) Loss: 1.7447 Acc@1: 60.09 Acc@5: 81.86 time: 305.6056
[2021-11-11 14:44:29] epoch[1](6000/20000) Loss: 1.7483 Acc@1: 60.04 Acc@5: 81.83 time: 309.1032
[2021-11-11 14:49:35] epoch[1](8000/20000) Loss: 1.7548 Acc@1: 59.92 Acc@5: 81.72 time: 305.3212
[2021-11-11 14:54:39] epoch[1](10000/20000) Loss: 1.7585 Acc@1: 59.84 Acc@5: 81.68 time: 304.8809
[2021-11-11 14:59:45] epoch[1](12000/20000) Loss: 1.7606 Acc@1: 59.80 Acc@5: 81.66 time: 305.2989
[2021-11-11 15:04:50] epoch[1](14000/20000) Loss: 1.7626 Acc@1: 59.75 Acc@5: 81.63 time: 304.8344
[2021-11-11 15:09:54] epoch[1](16000/20000) Loss: 1.7650 Acc@1: 59.73 Acc@5: 81.60 time: 304.7740
[2021-11-11 15:15:00] epoch[1](18000/20000) Loss: 1.7666 Acc@1: 59.71 Acc@5: 81.58 time: 305.3206
[2021-11-11 15:20:06] epoch[1](20000/20000) Loss: 1.7691 Acc@1: 59.67 Acc@5: 81.54 time: 305.8913
[2021-11-11 15:20:09] train    Loss: 1.7691 Acc@1: 59.67 Acc@5: 81.54 time: 3065.3716
[2021-11-11 15:21:25] validate Loss: 1.4427 Acc@1: 64.82 Acc@5: 86.72 time: 75.8321
[2021-11-11 15:21:25] epoch 2 learning_rate 0.001 
[2021-11-11 15:26:35] epoch[2](2000/20000) Loss: 1.7637 Acc@1: 59.77 Acc@5: 81.58 time: 310.9392
[2021-11-11 15:31:43] epoch[2](4000/20000) Loss: 1.7658 Acc@1: 59.67 Acc@5: 81.61 time: 307.7778
[2021-11-11 15:36:48] epoch[2](6000/20000) Loss: 1.7660 Acc@1: 59.76 Acc@5: 81.60 time: 304.6210
[2021-11-11 15:41:53] epoch[2](8000/20000) Loss: 1.7711 Acc@1: 59.72 Acc@5: 81.54 time: 304.8077
[2021-11-11 15:46:58] epoch[2](10000/20000) Loss: 1.7752 Acc@1: 59.65 Acc@5: 81.49 time: 305.4514
[2021-11-11 15:52:03] epoch[2](12000/20000) Loss: 1.7754 Acc@1: 59.65 Acc@5: 81.52 time: 305.1261
[2021-11-11 15:57:08] epoch[2](14000/20000) Loss: 1.7769 Acc@1: 59.63 Acc@5: 81.50 time: 304.9762
[2021-11-11 16:02:14] epoch[2](16000/20000) Loss: 1.7792 Acc@1: 59.59 Acc@5: 81.47 time: 305.6828
[2021-11-11 16:07:20] epoch[2](18000/20000) Loss: 1.7806 Acc@1: 59.57 Acc@5: 81.47 time: 305.5629
[2021-11-11 16:12:24] epoch[2](20000/20000) Loss: 1.7839 Acc@1: 59.50 Acc@5: 81.42 time: 304.8570
[2021-11-11 16:12:27] train    Loss: 1.7839 Acc@1: 59.50 Acc@5: 81.42 time: 3062.9245
[2021-11-11 16:13:44] validate Loss: 1.4530 Acc@1: 64.68 Acc@5: 86.63 time: 76.2987
[2021-11-11 16:13:44] epoch 3 learning_rate 0.001 
[2021-11-11 16:18:55] epoch[3](2000/20000) Loss: 1.7831 Acc@1: 59.55 Acc@5: 81.55 time: 310.8969
[2021-11-11 16:24:00] epoch[3](4000/20000) Loss: 1.7843 Acc@1: 59.51 Acc@5: 81.47 time: 305.4174
[2021-11-11 16:29:06] epoch[3](6000/20000) Loss: 1.7863 Acc@1: 59.42 Acc@5: 81.41 time: 305.8229
[2021-11-11 16:34:11] epoch[3](8000/20000) Loss: 1.7905 Acc@1: 59.40 Acc@5: 81.35 time: 305.4945
[2021-11-11 16:39:17] epoch[3](10000/20000) Loss: 1.7959 Acc@1: 59.31 Acc@5: 81.28 time: 305.1368
[2021-11-11 16:44:22] epoch[3](12000/20000) Loss: 1.8004 Acc@1: 59.22 Acc@5: 81.21 time: 305.8182
[2021-11-11 16:49:28] epoch[3](14000/20000) Loss: 1.8019 Acc@1: 59.19 Acc@5: 81.19 time: 305.3232
[2021-11-11 16:54:34] epoch[3](16000/20000) Loss: 1.8046 Acc@1: 59.14 Acc@5: 81.15 time: 305.8829
[2021-11-11 16:59:43] epoch[3](18000/20000) Loss: 1.8071 Acc@1: 59.07 Acc@5: 81.11 time: 309.9055
[2021-11-11 17:04:49] epoch[3](20000/20000) Loss: 1.8095 Acc@1: 59.03 Acc@5: 81.08 time: 305.3359
[2021-11-11 17:04:52] train    Loss: 1.8096 Acc@1: 59.03 Acc@5: 81.08 time: 3068.1695
[2021-11-11 17:06:07] validate Loss: 1.4931 Acc@1: 63.65 Acc@5: 86.01 time: 75.5265
[2021-11-11 17:06:07] epoch 4 learning_rate 0.001 
[2021-11-11 17:11:20] epoch[4](2000/20000) Loss: 1.8070 Acc@1: 59.06 Acc@5: 81.22 time: 312.5088
[2021-11-11 17:16:26] epoch[4](4000/20000) Loss: 1.8082 Acc@1: 59.10 Acc@5: 81.14 time: 306.3818
[2021-11-11 17:21:32] epoch[4](6000/20000) Loss: 1.8150 Acc@1: 58.99 Acc@5: 81.06 time: 305.5719
[2021-11-11 17:26:37] epoch[4](8000/20000) Loss: 1.8164 Acc@1: 58.97 Acc@5: 81.02 time: 305.5269
[2021-11-11 17:31:43] epoch[4](10000/20000) Loss: 1.8186 Acc@1: 58.93 Acc@5: 81.00 time: 305.8400
[2021-11-11 17:36:49] epoch[4](12000/20000) Loss: 1.8225 Acc@1: 58.84 Acc@5: 80.93 time: 305.7122
[2021-11-11 17:41:54] epoch[4](14000/20000) Loss: 1.8270 Acc@1: 58.74 Acc@5: 80.86 time: 305.3109
[2021-11-11 17:47:00] epoch[4](16000/20000) Loss: 1.8280 Acc@1: 58.71 Acc@5: 80.87 time: 305.6761
[2021-11-11 17:52:06] epoch[4](18000/20000) Loss: 1.8307 Acc@1: 58.65 Acc@5: 80.83 time: 305.7568
[2021-11-11 17:57:11] epoch[4](20000/20000) Loss: 1.8328 Acc@1: 58.59 Acc@5: 80.80 time: 305.5379
[2021-11-11 17:57:14] train    Loss: 1.8328 Acc@1: 58.59 Acc@5: 80.80 time: 3066.9545
[2021-11-11 17:58:31] validate Loss: 1.4866 Acc@1: 63.82 Acc@5: 86.19 time: 76.1696
[2021-11-11 17:58:31] epoch 5 learning_rate 0.0001 
[2021-11-11 18:03:42] epoch[5](2000/20000) Loss: 1.7189 Acc@1: 61.06 Acc@5: 82.58 time: 311.2719
[2021-11-11 18:08:47] epoch[5](4000/20000) Loss: 1.6912 Acc@1: 61.61 Acc@5: 82.90 time: 305.3996
[2021-11-11 18:13:53] epoch[5](6000/20000) Loss: 1.6764 Acc@1: 61.93 Acc@5: 83.07 time: 305.4606
[2021-11-11 18:18:58] epoch[5](8000/20000) Loss: 1.6654 Acc@1: 62.18 Acc@5: 83.20 time: 305.1892
[2021-11-11 18:24:04] epoch[5](10000/20000) Loss: 1.6577 Acc@1: 62.32 Acc@5: 83.31 time: 305.9798
[2021-11-11 18:29:10] epoch[5](12000/20000) Loss: 1.6513 Acc@1: 62.45 Acc@5: 83.40 time: 305.6798
[2021-11-11 18:34:20] epoch[5](14000/20000) Loss: 1.6453 Acc@1: 62.57 Acc@5: 83.49 time: 310.1166
[2021-11-11 18:39:27] epoch[5](16000/20000) Loss: 1.6409 Acc@1: 62.67 Acc@5: 83.54 time: 307.3064
[2021-11-11 18:44:32] epoch[5](18000/20000) Loss: 1.6369 Acc@1: 62.75 Acc@5: 83.59 time: 305.3438
[2021-11-11 18:49:38] epoch[5](20000/20000) Loss: 1.6329 Acc@1: 62.83 Acc@5: 83.64 time: 305.8168
[2021-11-11 18:49:41] train    Loss: 1.6329 Acc@1: 62.83 Acc@5: 83.64 time: 3070.7224
[2021-11-11 18:50:57] validate Loss: 1.2964 Acc@1: 68.05 Acc@5: 88.66 time: 75.9492
[2021-11-11 18:50:57] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-11 18:50:57] epoch 6 learning_rate 0.0001 
[2021-11-11 18:56:09] epoch[6](2000/20000) Loss: 1.5879 Acc@1: 63.76 Acc@5: 84.26 time: 311.4141
[2021-11-11 19:01:14] epoch[6](4000/20000) Loss: 1.5874 Acc@1: 63.76 Acc@5: 84.25 time: 305.3603
[2021-11-11 19:06:20] epoch[6](6000/20000) Loss: 1.5884 Acc@1: 63.72 Acc@5: 84.25 time: 305.5293
[2021-11-11 19:11:25] epoch[6](8000/20000) Loss: 1.5902 Acc@1: 63.72 Acc@5: 84.20 time: 304.9271
[2021-11-11 19:16:30] epoch[6](10000/20000) Loss: 1.5888 Acc@1: 63.78 Acc@5: 84.22 time: 305.5013
[2021-11-11 19:21:35] epoch[6](12000/20000) Loss: 1.5874 Acc@1: 63.81 Acc@5: 84.26 time: 305.3587
[2021-11-11 19:26:41] epoch[6](14000/20000) Loss: 1.5862 Acc@1: 63.82 Acc@5: 84.25 time: 305.3765
[2021-11-11 19:31:46] epoch[6](16000/20000) Loss: 1.5860 Acc@1: 63.82 Acc@5: 84.26 time: 305.2874
[2021-11-11 19:36:51] epoch[6](18000/20000) Loss: 1.5856 Acc@1: 63.82 Acc@5: 84.26 time: 305.3527
[2021-11-11 19:41:56] epoch[6](20000/20000) Loss: 1.5854 Acc@1: 63.82 Acc@5: 84.27 time: 305.0472
[2021-11-11 19:42:00] train    Loss: 1.5854 Acc@1: 63.82 Acc@5: 84.27 time: 3062.2857
[2021-11-11 19:43:16] validate Loss: 1.2786 Acc@1: 68.43 Acc@5: 89.00 time: 76.2801
[2021-11-11 19:43:16] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-11 19:43:16] epoch 7 learning_rate 0.0001 
[2021-11-11 19:48:29] epoch[7](2000/20000) Loss: 1.5703 Acc@1: 64.27 Acc@5: 84.43 time: 313.3026
[2021-11-11 19:53:35] epoch[7](4000/20000) Loss: 1.5695 Acc@1: 64.20 Acc@5: 84.42 time: 305.3775
[2021-11-11 19:58:41] epoch[7](6000/20000) Loss: 1.5711 Acc@1: 64.15 Acc@5: 84.43 time: 306.0143
[2021-11-11 20:03:48] epoch[7](8000/20000) Loss: 1.5667 Acc@1: 64.26 Acc@5: 84.51 time: 307.4211
[2021-11-11 20:08:54] epoch[7](10000/20000) Loss: 1.5657 Acc@1: 64.30 Acc@5: 84.53 time: 305.7781
[2021-11-11 20:13:59] epoch[7](12000/20000) Loss: 1.5663 Acc@1: 64.28 Acc@5: 84.54 time: 305.4605
[2021-11-11 20:19:05] epoch[7](14000/20000) Loss: 1.5657 Acc@1: 64.27 Acc@5: 84.56 time: 305.2351
[2021-11-11 20:24:10] epoch[7](16000/20000) Loss: 1.5670 Acc@1: 64.25 Acc@5: 84.54 time: 305.4391
[2021-11-11 20:29:19] epoch[7](18000/20000) Loss: 1.5669 Acc@1: 64.25 Acc@5: 84.53 time: 309.3363
[2021-11-11 20:34:25] epoch[7](20000/20000) Loss: 1.5652 Acc@1: 64.29 Acc@5: 84.55 time: 305.7102
[2021-11-11 20:34:28] train    Loss: 1.5652 Acc@1: 64.29 Acc@5: 84.55 time: 3072.2031
[2021-11-11 20:35:44] validate Loss: 1.2738 Acc@1: 68.68 Acc@5: 88.88 time: 75.7618
[2021-11-11 20:35:44] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-11 20:35:44] epoch 8 learning_rate 0.0001 
[2021-11-11 20:40:56] epoch[8](2000/20000) Loss: 1.5460 Acc@1: 64.47 Acc@5: 84.79 time: 311.5122
[2021-11-11 20:46:02] epoch[8](4000/20000) Loss: 1.5447 Acc@1: 64.60 Acc@5: 84.81 time: 306.2945
[2021-11-11 20:51:10] epoch[8](6000/20000) Loss: 1.5468 Acc@1: 64.56 Acc@5: 84.78 time: 308.0995
[2021-11-11 20:56:15] epoch[8](8000/20000) Loss: 1.5480 Acc@1: 64.54 Acc@5: 84.81 time: 305.5489
[2021-11-11 21:01:21] epoch[8](10000/20000) Loss: 1.5509 Acc@1: 64.49 Acc@5: 84.76 time: 305.2715
[2021-11-11 21:06:26] epoch[8](12000/20000) Loss: 1.5526 Acc@1: 64.46 Acc@5: 84.73 time: 304.9434
[2021-11-11 21:11:31] epoch[8](14000/20000) Loss: 1.5528 Acc@1: 64.47 Acc@5: 84.72 time: 305.8297
[2021-11-11 21:16:37] epoch[8](16000/20000) Loss: 1.5545 Acc@1: 64.45 Acc@5: 84.69 time: 305.2436
[2021-11-11 21:21:42] epoch[8](18000/20000) Loss: 1.5545 Acc@1: 64.45 Acc@5: 84.69 time: 305.1332
[2021-11-11 21:26:47] epoch[8](20000/20000) Loss: 1.5553 Acc@1: 64.43 Acc@5: 84.69 time: 305.2538
[2021-11-11 21:26:50] train    Loss: 1.5552 Acc@1: 64.43 Acc@5: 84.69 time: 3066.2597
[2021-11-11 21:28:07] validate Loss: 1.2630 Acc@1: 68.87 Acc@5: 89.10 time: 76.7988
[2021-11-11 21:28:07] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-11 21:28:07] epoch 9 learning_rate 0.0001 
[2021-11-11 21:33:18] epoch[9](2000/20000) Loss: 1.5501 Acc@1: 64.57 Acc@5: 84.77 time: 311.3415
[2021-11-11 21:38:24] epoch[9](4000/20000) Loss: 1.5486 Acc@1: 64.64 Acc@5: 84.81 time: 305.0716
[2021-11-11 21:43:29] epoch[9](6000/20000) Loss: 1.5449 Acc@1: 64.70 Acc@5: 84.90 time: 305.6505
[2021-11-11 21:48:35] epoch[9](8000/20000) Loss: 1.5452 Acc@1: 64.71 Acc@5: 84.89 time: 305.9442
[2021-11-11 21:53:41] epoch[9](10000/20000) Loss: 1.5459 Acc@1: 64.69 Acc@5: 84.88 time: 305.7388
[2021-11-11 21:58:46] epoch[9](12000/20000) Loss: 1.5459 Acc@1: 64.64 Acc@5: 84.87 time: 305.2739
[2021-11-11 22:03:52] epoch[9](14000/20000) Loss: 1.5465 Acc@1: 64.66 Acc@5: 84.85 time: 305.5618
[2021-11-11 22:08:57] epoch[9](16000/20000) Loss: 1.5459 Acc@1: 64.66 Acc@5: 84.86 time: 305.3884
[2021-11-11 22:14:03] epoch[9](18000/20000) Loss: 1.5452 Acc@1: 64.66 Acc@5: 84.88 time: 305.5491
[2021-11-11 22:19:08] epoch[9](20000/20000) Loss: 1.5452 Acc@1: 64.67 Acc@5: 84.86 time: 305.6731
[2021-11-11 22:19:11] train    Loss: 1.5452 Acc@1: 64.67 Acc@5: 84.87 time: 3064.3137
[2021-11-11 22:20:27] validate Loss: 1.2562 Acc@1: 69.06 Acc@5: 89.13 time: 75.8260
[2021-11-11 22:20:27] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-11 22:20:27] epoch 10 learning_rate 0.0001 
[2021-11-11 22:25:39] epoch[10](2000/20000) Loss: 1.5443 Acc@1: 64.77 Acc@5: 84.85 time: 311.5981
[2021-11-11 22:30:45] epoch[10](4000/20000) Loss: 1.5433 Acc@1: 64.85 Acc@5: 84.80 time: 305.8067
[2021-11-11 22:35:50] epoch[10](6000/20000) Loss: 1.5408 Acc@1: 64.86 Acc@5: 84.85 time: 305.7499
[2021-11-11 22:40:57] epoch[10](8000/20000) Loss: 1.5404 Acc@1: 64.87 Acc@5: 84.86 time: 306.2549
[2021-11-11 22:46:02] epoch[10](10000/20000) Loss: 1.5398 Acc@1: 64.86 Acc@5: 84.86 time: 305.3974
[2021-11-11 22:51:13] epoch[10](12000/20000) Loss: 1.5393 Acc@1: 64.86 Acc@5: 84.87 time: 310.7856
[2021-11-11 22:56:18] epoch[10](14000/20000) Loss: 1.5399 Acc@1: 64.85 Acc@5: 84.88 time: 305.3574
[2021-11-11 23:01:24] epoch[10](16000/20000) Loss: 1.5399 Acc@1: 64.82 Acc@5: 84.88 time: 305.3263
[2021-11-11 23:06:35] epoch[10](18000/20000) Loss: 1.5396 Acc@1: 64.82 Acc@5: 84.89 time: 311.5569
[2021-11-11 23:11:41] epoch[10](20000/20000) Loss: 1.5406 Acc@1: 64.81 Acc@5: 84.87 time: 305.7583
[2021-11-11 23:11:44] train    Loss: 1.5406 Acc@1: 64.81 Acc@5: 84.87 time: 3076.7696
[2021-11-11 23:13:00] validate Loss: 1.2489 Acc@1: 69.28 Acc@5: 89.28 time: 76.1583
[2021-11-11 23:13:00] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-11 23:13:00] epoch 11 learning_rate 0.0001 
[2021-11-11 23:18:12] epoch[11](2000/20000) Loss: 1.5277 Acc@1: 65.11 Acc@5: 85.06 time: 311.5535
[2021-11-11 23:23:18] epoch[11](4000/20000) Loss: 1.5294 Acc@1: 65.12 Acc@5: 85.00 time: 305.7864
[2021-11-11 23:28:23] epoch[11](6000/20000) Loss: 1.5288 Acc@1: 65.11 Acc@5: 85.00 time: 304.9695
[2021-11-11 23:33:28] epoch[11](8000/20000) Loss: 1.5308 Acc@1: 65.06 Acc@5: 84.96 time: 305.6336
[2021-11-11 23:38:34] epoch[11](10000/20000) Loss: 1.5322 Acc@1: 65.03 Acc@5: 84.95 time: 305.4970
[2021-11-11 23:43:39] epoch[11](12000/20000) Loss: 1.5326 Acc@1: 65.00 Acc@5: 84.98 time: 305.5906
[2021-11-11 23:48:45] epoch[11](14000/20000) Loss: 1.5319 Acc@1: 65.00 Acc@5: 85.00 time: 305.7622
[2021-11-11 23:53:54] epoch[11](16000/20000) Loss: 1.5335 Acc@1: 64.96 Acc@5: 84.98 time: 309.3264
[2021-11-11 23:59:00] epoch[11](18000/20000) Loss: 1.5335 Acc@1: 64.95 Acc@5: 84.98 time: 305.8212
[2021-11-12 00:04:06] epoch[11](20000/20000) Loss: 1.5332 Acc@1: 64.94 Acc@5: 84.99 time: 305.3529
[2021-11-12 00:04:09] train    Loss: 1.5333 Acc@1: 64.94 Acc@5: 84.99 time: 3068.4258
[2021-11-12 00:05:24] validate Loss: 1.2506 Acc@1: 69.07 Acc@5: 89.25 time: 75.6435
[2021-11-12 00:05:24] epoch 12 learning_rate 0.0001 
[2021-11-12 00:10:36] epoch[12](2000/20000) Loss: 1.5228 Acc@1: 65.19 Acc@5: 85.16 time: 311.3615
[2021-11-12 00:15:41] epoch[12](4000/20000) Loss: 1.5298 Acc@1: 65.02 Acc@5: 85.05 time: 305.3623
[2021-11-12 00:20:47] epoch[12](6000/20000) Loss: 1.5279 Acc@1: 65.05 Acc@5: 85.09 time: 305.8194
[2021-11-12 00:25:52] epoch[12](8000/20000) Loss: 1.5259 Acc@1: 65.10 Acc@5: 85.11 time: 305.5524
[2021-11-12 00:30:58] epoch[12](10000/20000) Loss: 1.5285 Acc@1: 65.03 Acc@5: 85.07 time: 305.8994
[2021-11-12 00:36:04] epoch[12](12000/20000) Loss: 1.5283 Acc@1: 65.04 Acc@5: 85.07 time: 305.4592
[2021-11-12 00:41:09] epoch[12](14000/20000) Loss: 1.5292 Acc@1: 65.05 Acc@5: 85.05 time: 305.3007
[2021-11-12 00:46:15] epoch[12](16000/20000) Loss: 1.5308 Acc@1: 65.01 Acc@5: 85.03 time: 305.8571
[2021-11-12 00:51:24] epoch[12](18000/20000) Loss: 1.5305 Acc@1: 65.01 Acc@5: 85.03 time: 308.6633
[2021-11-12 00:56:29] epoch[12](20000/20000) Loss: 1.5309 Acc@1: 64.99 Acc@5: 85.03 time: 305.2099
[2021-11-12 00:56:32] train    Loss: 1.5309 Acc@1: 64.99 Acc@5: 85.03 time: 3067.5945
[2021-11-12 00:57:52] validate Loss: 1.2416 Acc@1: 69.32 Acc@5: 89.26 time: 79.9593
[2021-11-12 00:57:52] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-12 00:57:52] epoch 13 learning_rate 0.0001 
[2021-11-12 01:03:03] epoch[13](2000/20000) Loss: 1.5256 Acc@1: 65.12 Acc@5: 85.01 time: 310.9522
[2021-11-12 01:08:08] epoch[13](4000/20000) Loss: 1.5277 Acc@1: 65.03 Acc@5: 85.05 time: 305.4252
[2021-11-12 01:13:14] epoch[13](6000/20000) Loss: 1.5253 Acc@1: 65.09 Acc@5: 85.10 time: 305.8240
[2021-11-12 01:18:19] epoch[13](8000/20000) Loss: 1.5260 Acc@1: 65.10 Acc@5: 85.08 time: 305.1204
[2021-11-12 01:23:25] epoch[13](10000/20000) Loss: 1.5257 Acc@1: 65.09 Acc@5: 85.10 time: 305.5218
[2021-11-12 01:28:30] epoch[13](12000/20000) Loss: 1.5242 Acc@1: 65.14 Acc@5: 85.10 time: 305.4989
[2021-11-12 01:33:36] epoch[13](14000/20000) Loss: 1.5249 Acc@1: 65.12 Acc@5: 85.10 time: 305.7666
[2021-11-12 01:38:41] epoch[13](16000/20000) Loss: 1.5248 Acc@1: 65.12 Acc@5: 85.11 time: 305.2080
[2021-11-12 01:43:47] epoch[13](18000/20000) Loss: 1.5261 Acc@1: 65.10 Acc@5: 85.09 time: 305.4351
[2021-11-12 01:48:52] epoch[13](20000/20000) Loss: 1.5273 Acc@1: 65.08 Acc@5: 85.07 time: 305.3963
[2021-11-12 01:48:55] train    Loss: 1.5273 Acc@1: 65.07 Acc@5: 85.07 time: 3063.2608
[2021-11-12 01:50:13] validate Loss: 1.2412 Acc@1: 69.38 Acc@5: 89.35 time: 77.8940
[2021-11-12 01:50:13] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-12 01:50:13] epoch 14 learning_rate 0.0001 
[2021-11-12 01:55:25] epoch[14](2000/20000) Loss: 1.5086 Acc@1: 65.49 Acc@5: 85.35 time: 311.5650
[2021-11-12 02:00:34] epoch[14](4000/20000) Loss: 1.5114 Acc@1: 65.40 Acc@5: 85.34 time: 308.9952
[2021-11-12 02:05:39] epoch[14](6000/20000) Loss: 1.5183 Acc@1: 65.24 Acc@5: 85.22 time: 304.9564
[2021-11-12 02:10:44] epoch[14](8000/20000) Loss: 1.5179 Acc@1: 65.25 Acc@5: 85.23 time: 305.4379
[2021-11-12 02:15:52] epoch[14](10000/20000) Loss: 1.5174 Acc@1: 65.21 Acc@5: 85.26 time: 307.3827
[2021-11-12 02:20:57] epoch[14](12000/20000) Loss: 1.5172 Acc@1: 65.23 Acc@5: 85.27 time: 304.9842
[2021-11-12 02:26:05] epoch[14](14000/20000) Loss: 1.5171 Acc@1: 65.23 Acc@5: 85.26 time: 308.0919
[2021-11-12 02:31:10] epoch[14](16000/20000) Loss: 1.5179 Acc@1: 65.20 Acc@5: 85.24 time: 305.1217
[2021-11-12 02:36:15] epoch[14](18000/20000) Loss: 1.5189 Acc@1: 65.19 Acc@5: 85.22 time: 305.4338
[2021-11-12 02:41:20] epoch[14](20000/20000) Loss: 1.5197 Acc@1: 65.17 Acc@5: 85.19 time: 304.8211
[2021-11-12 02:41:23] train    Loss: 1.5198 Acc@1: 65.17 Acc@5: 85.19 time: 3069.9095
[2021-11-12 02:42:41] validate Loss: 1.2390 Acc@1: 69.34 Acc@5: 89.41 time: 77.6029
[2021-11-12 02:42:41] epoch 15 learning_rate 0.0001 
[2021-11-12 02:47:53] epoch[15](2000/20000) Loss: 1.5040 Acc@1: 65.59 Acc@5: 85.44 time: 312.6025
[2021-11-12 02:53:01] epoch[15](4000/20000) Loss: 1.5115 Acc@1: 65.38 Acc@5: 85.29 time: 308.1387
[2021-11-12 02:58:07] epoch[15](6000/20000) Loss: 1.5135 Acc@1: 65.34 Acc@5: 85.25 time: 305.2382
[2021-11-12 03:03:12] epoch[15](8000/20000) Loss: 1.5133 Acc@1: 65.36 Acc@5: 85.25 time: 305.7826
[2021-11-12 03:08:18] epoch[15](10000/20000) Loss: 1.5155 Acc@1: 65.32 Acc@5: 85.23 time: 305.1069
[2021-11-12 03:13:23] epoch[15](12000/20000) Loss: 1.5154 Acc@1: 65.32 Acc@5: 85.23 time: 305.5560
[2021-11-12 03:18:28] epoch[15](14000/20000) Loss: 1.5159 Acc@1: 65.31 Acc@5: 85.22 time: 305.2301
[2021-11-12 03:23:34] epoch[15](16000/20000) Loss: 1.5156 Acc@1: 65.30 Acc@5: 85.22 time: 305.2337
[2021-11-12 03:28:42] epoch[15](18000/20000) Loss: 1.5165 Acc@1: 65.29 Acc@5: 85.21 time: 308.2453
[2021-11-12 03:33:47] epoch[15](20000/20000) Loss: 1.5166 Acc@1: 65.28 Acc@5: 85.21 time: 305.0888
[2021-11-12 03:33:50] train    Loss: 1.5165 Acc@1: 65.29 Acc@5: 85.21 time: 3069.3558
[2021-11-12 03:35:06] validate Loss: 1.2371 Acc@1: 69.36 Acc@5: 89.40 time: 75.9067
[2021-11-12 03:35:06] epoch 16 learning_rate 0.0001 
[2021-11-12 03:40:18] epoch[16](2000/20000) Loss: 1.5076 Acc@1: 65.65 Acc@5: 85.37 time: 311.5809
[2021-11-12 03:45:23] epoch[16](4000/20000) Loss: 1.5083 Acc@1: 65.56 Acc@5: 85.32 time: 305.7152
[2021-11-12 03:50:29] epoch[16](6000/20000) Loss: 1.5079 Acc@1: 65.51 Acc@5: 85.30 time: 305.7456
[2021-11-12 03:55:34] epoch[16](8000/20000) Loss: 1.5110 Acc@1: 65.42 Acc@5: 85.26 time: 305.3440
[2021-11-12 04:00:44] epoch[16](10000/20000) Loss: 1.5119 Acc@1: 65.42 Acc@5: 85.28 time: 309.7602
[2021-11-12 04:05:49] epoch[16](12000/20000) Loss: 1.5124 Acc@1: 65.40 Acc@5: 85.28 time: 305.1048
[2021-11-12 04:10:55] epoch[16](14000/20000) Loss: 1.5125 Acc@1: 65.39 Acc@5: 85.29 time: 305.5797
[2021-11-12 04:16:01] epoch[16](16000/20000) Loss: 1.5123 Acc@1: 65.39 Acc@5: 85.28 time: 305.7081
[2021-11-12 04:21:06] epoch[16](18000/20000) Loss: 1.5134 Acc@1: 65.36 Acc@5: 85.27 time: 305.4848
[2021-11-12 04:26:11] epoch[16](20000/20000) Loss: 1.5140 Acc@1: 65.32 Acc@5: 85.27 time: 305.3530
[2021-11-12 04:26:14] train    Loss: 1.5140 Acc@1: 65.32 Acc@5: 85.27 time: 3068.4880
[2021-11-12 04:27:31] validate Loss: 1.2402 Acc@1: 69.36 Acc@5: 89.29 time: 76.2151
[2021-11-12 04:27:31] epoch 17 learning_rate 0.0001 
[2021-11-12 04:32:42] epoch[17](2000/20000) Loss: 1.5047 Acc@1: 65.49 Acc@5: 85.50 time: 311.4378
[2021-11-12 04:37:48] epoch[17](4000/20000) Loss: 1.5036 Acc@1: 65.48 Acc@5: 85.48 time: 305.4229
[2021-11-12 04:42:53] epoch[17](6000/20000) Loss: 1.5095 Acc@1: 65.38 Acc@5: 85.36 time: 305.4075
[2021-11-12 04:47:58] epoch[17](8000/20000) Loss: 1.5139 Acc@1: 65.30 Acc@5: 85.27 time: 305.0954
[2021-11-12 04:53:03] epoch[17](10000/20000) Loss: 1.5129 Acc@1: 65.35 Acc@5: 85.26 time: 305.1713
[2021-11-12 04:58:12] epoch[17](12000/20000) Loss: 1.5123 Acc@1: 65.33 Acc@5: 85.28 time: 308.2942
[2021-11-12 05:03:16] epoch[17](14000/20000) Loss: 1.5117 Acc@1: 65.35 Acc@5: 85.29 time: 304.9246
[2021-11-12 05:08:22] epoch[17](16000/20000) Loss: 1.5122 Acc@1: 65.35 Acc@5: 85.27 time: 305.8223
[2021-11-12 05:13:27] epoch[17](18000/20000) Loss: 1.5122 Acc@1: 65.35 Acc@5: 85.28 time: 305.1558
[2021-11-12 05:18:33] epoch[17](20000/20000) Loss: 1.5120 Acc@1: 65.36 Acc@5: 85.29 time: 305.1361
[2021-11-12 05:18:36] train    Loss: 1.5120 Acc@1: 65.36 Acc@5: 85.29 time: 3065.0251
[2021-11-12 05:19:52] validate Loss: 1.2305 Acc@1: 69.45 Acc@5: 89.47 time: 76.1007
[2021-11-12 05:19:52] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-12 05:19:52] epoch 18 learning_rate 0.0001 
[2021-11-12 05:25:03] epoch[18](2000/20000) Loss: 1.5011 Acc@1: 65.81 Acc@5: 85.32 time: 311.5016
[2021-11-12 05:30:09] epoch[18](4000/20000) Loss: 1.5010 Acc@1: 65.66 Acc@5: 85.42 time: 305.3256
[2021-11-12 05:35:14] epoch[18](6000/20000) Loss: 1.5038 Acc@1: 65.59 Acc@5: 85.39 time: 305.5450
[2021-11-12 05:40:20] epoch[18](8000/20000) Loss: 1.5037 Acc@1: 65.59 Acc@5: 85.42 time: 305.4898
[2021-11-12 05:45:30] epoch[18](10000/20000) Loss: 1.5053 Acc@1: 65.58 Acc@5: 85.39 time: 310.4794
[2021-11-12 05:50:36] epoch[18](12000/20000) Loss: 1.5064 Acc@1: 65.56 Acc@5: 85.39 time: 305.5504
[2021-11-12 05:55:44] epoch[18](14000/20000) Loss: 1.5067 Acc@1: 65.54 Acc@5: 85.38 time: 308.5662
[2021-11-12 06:00:50] epoch[18](16000/20000) Loss: 1.5073 Acc@1: 65.53 Acc@5: 85.37 time: 305.3613
[2021-11-12 06:05:55] epoch[18](18000/20000) Loss: 1.5078 Acc@1: 65.51 Acc@5: 85.35 time: 305.2056
[2021-11-12 06:11:00] epoch[18](20000/20000) Loss: 1.5080 Acc@1: 65.50 Acc@5: 85.36 time: 305.4566
[2021-11-12 06:11:03] train    Loss: 1.5080 Acc@1: 65.50 Acc@5: 85.36 time: 3071.5837
[2021-11-12 06:12:20] validate Loss: 1.2328 Acc@1: 69.35 Acc@5: 89.42 time: 76.0828
[2021-11-12 06:12:20] epoch 19 learning_rate 0.0001 
[2021-11-12 06:17:31] epoch[19](2000/20000) Loss: 1.5117 Acc@1: 65.37 Acc@5: 85.31 time: 310.9800
[2021-11-12 06:22:36] epoch[19](4000/20000) Loss: 1.5110 Acc@1: 65.49 Acc@5: 85.24 time: 305.3032
[2021-11-12 06:27:41] epoch[19](6000/20000) Loss: 1.5033 Acc@1: 65.64 Acc@5: 85.37 time: 305.3728
[2021-11-12 06:32:47] epoch[19](8000/20000) Loss: 1.5035 Acc@1: 65.63 Acc@5: 85.38 time: 305.4753
[2021-11-12 06:37:52] epoch[19](10000/20000) Loss: 1.5018 Acc@1: 65.63 Acc@5: 85.40 time: 305.6185
[2021-11-12 06:43:06] epoch[19](12000/20000) Loss: 1.5031 Acc@1: 65.61 Acc@5: 85.38 time: 313.4034
[2021-11-12 06:48:11] epoch[19](14000/20000) Loss: 1.5034 Acc@1: 65.59 Acc@5: 85.37 time: 305.1205
[2021-11-12 06:53:16] epoch[19](16000/20000) Loss: 1.5042 Acc@1: 65.55 Acc@5: 85.37 time: 305.4771
[2021-11-12 06:58:21] epoch[19](18000/20000) Loss: 1.5050 Acc@1: 65.53 Acc@5: 85.35 time: 305.1361
[2021-11-12 07:03:27] epoch[19](20000/20000) Loss: 1.5057 Acc@1: 65.51 Acc@5: 85.35 time: 305.4391
[2021-11-12 07:03:30] train    Loss: 1.5057 Acc@1: 65.52 Acc@5: 85.35 time: 3070.4609
[2021-11-12 07:04:48] validate Loss: 1.2302 Acc@1: 69.42 Acc@5: 89.46 time: 77.5327
[2021-11-12 07:04:48] epoch 20 learning_rate 1e-05 
[2021-11-12 07:09:59] epoch[20](2000/20000) Loss: 1.4811 Acc@1: 65.97 Acc@5: 85.70 time: 311.7351
[2021-11-12 07:15:04] epoch[20](4000/20000) Loss: 1.4785 Acc@1: 66.10 Acc@5: 85.76 time: 305.0690
[2021-11-12 07:20:10] epoch[20](6000/20000) Loss: 1.4782 Acc@1: 66.12 Acc@5: 85.75 time: 305.5850
[2021-11-12 07:25:16] epoch[20](8000/20000) Loss: 1.4783 Acc@1: 66.13 Acc@5: 85.75 time: 305.7722
[2021-11-12 07:30:21] epoch[20](10000/20000) Loss: 1.4764 Acc@1: 66.15 Acc@5: 85.79 time: 305.5237
[2021-11-12 07:35:26] epoch[20](12000/20000) Loss: 1.4754 Acc@1: 66.17 Acc@5: 85.80 time: 305.0844
[2021-11-12 07:40:32] epoch[20](14000/20000) Loss: 1.4737 Acc@1: 66.22 Acc@5: 85.83 time: 305.6114
[2021-11-12 07:45:37] epoch[20](16000/20000) Loss: 1.4724 Acc@1: 66.24 Acc@5: 85.84 time: 305.1216
[2021-11-12 07:50:43] epoch[20](18000/20000) Loss: 1.4722 Acc@1: 66.23 Acc@5: 85.85 time: 305.6698
[2021-11-12 07:55:48] epoch[20](20000/20000) Loss: 1.4720 Acc@1: 66.23 Acc@5: 85.85 time: 305.3180
[2021-11-12 07:55:51] train    Loss: 1.4720 Acc@1: 66.23 Acc@5: 85.85 time: 3063.6610
[2021-11-12 07:57:08] validate Loss: 1.2087 Acc@1: 69.97 Acc@5: 89.73 time: 76.9890
[2021-11-12 07:57:08] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-12 07:57:08] epoch 21 learning_rate 1e-05 
[2021-11-12 08:02:19] epoch[21](2000/20000) Loss: 1.4607 Acc@1: 66.52 Acc@5: 85.99 time: 311.1367
[2021-11-12 08:07:25] epoch[21](4000/20000) Loss: 1.4618 Acc@1: 66.53 Acc@5: 85.94 time: 305.5931
[2021-11-12 08:12:30] epoch[21](6000/20000) Loss: 1.4659 Acc@1: 66.39 Acc@5: 85.93 time: 305.3695
[2021-11-12 08:17:36] epoch[21](8000/20000) Loss: 1.4652 Acc@1: 66.38 Acc@5: 85.93 time: 305.7442
[2021-11-12 08:22:41] epoch[21](10000/20000) Loss: 1.4645 Acc@1: 66.37 Acc@5: 85.95 time: 305.1924
[2021-11-12 08:27:47] epoch[21](12000/20000) Loss: 1.4629 Acc@1: 66.40 Acc@5: 85.98 time: 305.5557
[2021-11-12 08:32:52] epoch[21](14000/20000) Loss: 1.4633 Acc@1: 66.38 Acc@5: 85.97 time: 305.2846
[2021-11-12 08:37:58] epoch[21](16000/20000) Loss: 1.4621 Acc@1: 66.40 Acc@5: 85.98 time: 305.7260
[2021-11-12 08:43:03] epoch[21](18000/20000) Loss: 1.4631 Acc@1: 66.38 Acc@5: 85.96 time: 305.3008
[2021-11-12 08:48:09] epoch[21](20000/20000) Loss: 1.4632 Acc@1: 66.40 Acc@5: 85.95 time: 305.4690
[2021-11-12 08:48:12] train    Loss: 1.4632 Acc@1: 66.40 Acc@5: 85.95 time: 3063.5510
[2021-11-12 08:49:28] validate Loss: 1.2064 Acc@1: 70.05 Acc@5: 89.78 time: 75.9781
[2021-11-12 08:49:28] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-12 08:49:28] epoch 22 learning_rate 1e-05 
[2021-11-12 08:54:39] epoch[22](2000/20000) Loss: 1.4548 Acc@1: 66.68 Acc@5: 86.06 time: 311.4210
[2021-11-12 08:59:45] epoch[22](4000/20000) Loss: 1.4537 Acc@1: 66.65 Acc@5: 86.08 time: 305.4939
[2021-11-12 09:04:50] epoch[22](6000/20000) Loss: 1.4574 Acc@1: 66.52 Acc@5: 86.04 time: 304.9080
[2021-11-12 09:09:55] epoch[22](8000/20000) Loss: 1.4578 Acc@1: 66.50 Acc@5: 86.02 time: 305.3660
[2021-11-12 09:15:01] epoch[22](10000/20000) Loss: 1.4585 Acc@1: 66.53 Acc@5: 86.00 time: 305.6134
[2021-11-12 09:20:06] epoch[22](12000/20000) Loss: 1.4599 Acc@1: 66.51 Acc@5: 85.98 time: 305.5052
[2021-11-12 09:25:12] epoch[22](14000/20000) Loss: 1.4591 Acc@1: 66.53 Acc@5: 86.00 time: 305.6700
[2021-11-12 09:30:18] epoch[22](16000/20000) Loss: 1.4600 Acc@1: 66.51 Acc@5: 85.98 time: 305.7156
[2021-11-12 09:35:23] epoch[22](18000/20000) Loss: 1.4606 Acc@1: 66.49 Acc@5: 85.98 time: 305.7664
[2021-11-12 09:40:29] epoch[22](20000/20000) Loss: 1.4612 Acc@1: 66.48 Acc@5: 85.99 time: 305.5041
[2021-11-12 09:40:32] train    Loss: 1.4611 Acc@1: 66.49 Acc@5: 85.99 time: 3064.0696
[2021-11-12 09:41:48] validate Loss: 1.2048 Acc@1: 70.07 Acc@5: 89.76 time: 76.2067
[2021-11-12 09:41:48] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-12 09:41:48] epoch 23 learning_rate 1e-05 
[2021-11-12 09:46:59] epoch[23](2000/20000) Loss: 1.4573 Acc@1: 66.58 Acc@5: 86.14 time: 311.0113
[2021-11-12 09:52:05] epoch[23](4000/20000) Loss: 1.4581 Acc@1: 66.52 Acc@5: 86.07 time: 305.4365
[2021-11-12 09:57:10] epoch[23](6000/20000) Loss: 1.4557 Acc@1: 66.55 Acc@5: 86.09 time: 305.5623
[2021-11-12 10:02:15] epoch[23](8000/20000) Loss: 1.4572 Acc@1: 66.53 Acc@5: 86.07 time: 305.2525
[2021-11-12 10:07:21] epoch[23](10000/20000) Loss: 1.4575 Acc@1: 66.54 Acc@5: 86.04 time: 305.3520
[2021-11-12 10:12:28] epoch[23](12000/20000) Loss: 1.4585 Acc@1: 66.52 Acc@5: 86.03 time: 307.6119
[2021-11-12 10:17:34] epoch[23](14000/20000) Loss: 1.4576 Acc@1: 66.54 Acc@5: 86.04 time: 305.7817
[2021-11-12 10:22:40] epoch[23](16000/20000) Loss: 1.4581 Acc@1: 66.52 Acc@5: 86.04 time: 305.9701
[2021-11-12 10:27:46] epoch[23](18000/20000) Loss: 1.4594 Acc@1: 66.50 Acc@5: 86.01 time: 305.4930
[2021-11-12 10:32:51] epoch[23](20000/20000) Loss: 1.4596 Acc@1: 66.49 Acc@5: 86.01 time: 305.1680
[2021-11-12 10:32:54] train    Loss: 1.4597 Acc@1: 66.48 Acc@5: 86.01 time: 3065.7808
[2021-11-12 10:34:11] validate Loss: 1.1997 Acc@1: 70.16 Acc@5: 89.85 time: 76.6311
[2021-11-12 10:34:11] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-12 10:34:11] epoch 24 learning_rate 1e-05 
[2021-11-12 10:39:24] epoch[24](2000/20000) Loss: 1.4536 Acc@1: 66.67 Acc@5: 86.13 time: 313.5764
[2021-11-12 10:44:30] epoch[24](4000/20000) Loss: 1.4566 Acc@1: 66.59 Acc@5: 86.07 time: 305.3345
[2021-11-12 10:49:35] epoch[24](6000/20000) Loss: 1.4566 Acc@1: 66.61 Acc@5: 86.03 time: 305.0937
[2021-11-12 10:54:40] epoch[24](8000/20000) Loss: 1.4562 Acc@1: 66.61 Acc@5: 86.04 time: 305.6276
[2021-11-12 10:59:45] epoch[24](10000/20000) Loss: 1.4569 Acc@1: 66.59 Acc@5: 86.03 time: 305.1031
[2021-11-12 11:04:51] epoch[24](12000/20000) Loss: 1.4563 Acc@1: 66.59 Acc@5: 86.05 time: 305.3242
[2021-11-12 11:09:56] epoch[24](14000/20000) Loss: 1.4560 Acc@1: 66.60 Acc@5: 86.03 time: 305.2160
[2021-11-12 11:15:02] epoch[24](16000/20000) Loss: 1.4569 Acc@1: 66.60 Acc@5: 86.02 time: 305.6600
[2021-11-12 11:20:07] epoch[24](18000/20000) Loss: 1.4569 Acc@1: 66.59 Acc@5: 86.03 time: 305.2696
[2021-11-12 11:25:12] epoch[24](20000/20000) Loss: 1.4563 Acc@1: 66.59 Acc@5: 86.04 time: 305.1135
[2021-11-12 11:25:15] train    Loss: 1.4564 Acc@1: 66.59 Acc@5: 86.04 time: 3064.4468
[2021-11-12 11:26:32] validate Loss: 1.2018 Acc@1: 70.20 Acc@5: 89.83 time: 76.4696
[2021-11-12 11:26:32] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-12 11:26:32] epoch 25 learning_rate 1e-05 
[2021-11-12 11:31:43] epoch[25](2000/20000) Loss: 1.4557 Acc@1: 66.64 Acc@5: 86.01 time: 311.8308
[2021-11-12 11:36:49] epoch[25](4000/20000) Loss: 1.4547 Acc@1: 66.64 Acc@5: 86.02 time: 305.5385
[2021-11-12 11:41:54] epoch[25](6000/20000) Loss: 1.4553 Acc@1: 66.65 Acc@5: 86.01 time: 305.3560
[2021-11-12 11:47:00] epoch[25](8000/20000) Loss: 1.4557 Acc@1: 66.63 Acc@5: 86.02 time: 305.2788
[2021-11-12 11:52:05] epoch[25](10000/20000) Loss: 1.4558 Acc@1: 66.61 Acc@5: 86.02 time: 305.4182
[2021-11-12 11:57:11] epoch[25](12000/20000) Loss: 1.4553 Acc@1: 66.64 Acc@5: 86.03 time: 305.9105
[2021-11-12 12:02:16] epoch[25](14000/20000) Loss: 1.4543 Acc@1: 66.64 Acc@5: 86.04 time: 305.4108
[2021-11-12 12:07:21] epoch[25](16000/20000) Loss: 1.4547 Acc@1: 66.61 Acc@5: 86.04 time: 305.0819
[2021-11-12 12:12:27] epoch[25](18000/20000) Loss: 1.4548 Acc@1: 66.63 Acc@5: 86.04 time: 305.0479
[2021-11-12 12:17:35] epoch[25](20000/20000) Loss: 1.4548 Acc@1: 66.64 Acc@5: 86.04 time: 308.5076
[2021-11-12 12:17:38] train    Loss: 1.4548 Acc@1: 66.64 Acc@5: 86.04 time: 3066.4939
[2021-11-12 12:18:54] validate Loss: 1.2027 Acc@1: 70.20 Acc@5: 89.78 time: 76.0636
[2021-11-12 12:18:54] epoch 26 learning_rate 1e-05 
[2021-11-12 12:24:06] epoch[26](2000/20000) Loss: 1.4534 Acc@1: 66.59 Acc@5: 86.01 time: 311.4414
[2021-11-12 12:29:11] epoch[26](4000/20000) Loss: 1.4537 Acc@1: 66.69 Acc@5: 86.06 time: 305.4631
[2021-11-12 12:34:17] epoch[26](6000/20000) Loss: 1.4538 Acc@1: 66.67 Acc@5: 86.04 time: 305.8215
[2021-11-12 12:39:22] epoch[26](8000/20000) Loss: 1.4562 Acc@1: 66.62 Acc@5: 86.01 time: 305.2865
[2021-11-12 12:44:28] epoch[26](10000/20000) Loss: 1.4566 Acc@1: 66.61 Acc@5: 86.01 time: 305.4429
[2021-11-12 12:49:33] epoch[26](12000/20000) Loss: 1.4562 Acc@1: 66.61 Acc@5: 86.00 time: 305.8299
[2021-11-12 12:54:39] epoch[26](14000/20000) Loss: 1.4560 Acc@1: 66.63 Acc@5: 86.00 time: 305.3456
[2021-11-12 12:59:44] epoch[26](16000/20000) Loss: 1.4564 Acc@1: 66.61 Acc@5: 85.99 time: 305.6092
[2021-11-12 13:04:50] epoch[26](18000/20000) Loss: 1.4557 Acc@1: 66.62 Acc@5: 86.00 time: 305.5936
[2021-11-12 13:09:55] epoch[26](20000/20000) Loss: 1.4549 Acc@1: 66.64 Acc@5: 86.02 time: 305.2931
[2021-11-12 13:09:58] train    Loss: 1.4548 Acc@1: 66.64 Acc@5: 86.02 time: 3064.2337
[2021-11-12 13:11:15] validate Loss: 1.1994 Acc@1: 70.16 Acc@5: 89.83 time: 76.5257
[2021-11-12 13:11:15] epoch 27 learning_rate 1e-05 
[2021-11-12 13:16:26] epoch[27](2000/20000) Loss: 1.4551 Acc@1: 66.62 Acc@5: 86.12 time: 311.5445
[2021-11-12 13:21:32] epoch[27](4000/20000) Loss: 1.4517 Acc@1: 66.66 Acc@5: 86.13 time: 305.5045
[2021-11-12 13:26:37] epoch[27](6000/20000) Loss: 1.4560 Acc@1: 66.59 Acc@5: 86.05 time: 305.1897
[2021-11-12 13:31:43] epoch[27](8000/20000) Loss: 1.4556 Acc@1: 66.59 Acc@5: 86.04 time: 305.9722
[2021-11-12 13:36:52] epoch[27](10000/20000) Loss: 1.4555 Acc@1: 66.60 Acc@5: 86.03 time: 308.6490
[2021-11-12 13:41:57] epoch[27](12000/20000) Loss: 1.4562 Acc@1: 66.58 Acc@5: 86.04 time: 305.0457
[2021-11-12 13:47:02] epoch[27](14000/20000) Loss: 1.4557 Acc@1: 66.57 Acc@5: 86.03 time: 305.3078
[2021-11-12 13:52:08] epoch[27](16000/20000) Loss: 1.4548 Acc@1: 66.59 Acc@5: 86.06 time: 305.5440
[2021-11-12 13:57:13] epoch[27](18000/20000) Loss: 1.4555 Acc@1: 66.58 Acc@5: 86.04 time: 305.2118
[2021-11-12 14:02:18] epoch[27](20000/20000) Loss: 1.4554 Acc@1: 66.58 Acc@5: 86.04 time: 305.3920
[2021-11-12 14:02:21] train    Loss: 1.4555 Acc@1: 66.58 Acc@5: 86.04 time: 3066.4768
[2021-11-12 14:03:37] validate Loss: 1.1998 Acc@1: 70.26 Acc@5: 89.82 time: 76.0511
[2021-11-12 14:03:38] storing checkpoint:/pruned_checkpoint/resnet_50.pt
[2021-11-12 14:03:38] epoch 28 learning_rate 1e-05 
[2021-11-12 14:08:49] epoch[28](2000/20000) Loss: 1.4518 Acc@1: 66.74 Acc@5: 86.09 time: 311.6925
[2021-11-12 14:13:55] epoch[28](4000/20000) Loss: 1.4531 Acc@1: 66.65 Acc@5: 86.11 time: 305.7288
[2021-11-12 14:19:00] epoch[28](6000/20000) Loss: 1.4523 Acc@1: 66.69 Acc@5: 86.08 time: 305.3597
[2021-11-12 14:24:06] epoch[28](8000/20000) Loss: 1.4509 Acc@1: 66.74 Acc@5: 86.09 time: 305.5046
[2021-11-12 14:29:11] epoch[28](10000/20000) Loss: 1.4519 Acc@1: 66.70 Acc@5: 86.08 time: 305.1746
[2021-11-12 14:34:16] epoch[28](12000/20000) Loss: 1.4512 Acc@1: 66.70 Acc@5: 86.10 time: 305.3072
[2021-11-12 14:39:28] epoch[28](14000/20000) Loss: 1.4514 Acc@1: 66.70 Acc@5: 86.08 time: 312.0263
[2021-11-12 14:44:34] epoch[28](16000/20000) Loss: 1.4513 Acc@1: 66.69 Acc@5: 86.09 time: 305.8650
[2021-11-12 14:49:40] epoch[28](18000/20000) Loss: 1.4513 Acc@1: 66.70 Acc@5: 86.08 time: 305.4216
[2021-11-12 14:54:45] epoch[28](20000/20000) Loss: 1.4513 Acc@1: 66.69 Acc@5: 86.09 time: 305.4686
[2021-11-12 14:54:48] train    Loss: 1.4514 Acc@1: 66.69 Acc@5: 86.09 time: 3070.6580
[2021-11-12 14:56:04] validate Loss: 1.2009 Acc@1: 70.17 Acc@5: 89.77 time: 76.0805
[2021-11-12 14:56:04] epoch 29 learning_rate 1e-05 
[2021-11-12 15:01:16] epoch[29](2000/20000) Loss: 1.4434 Acc@1: 67.03 Acc@5: 86.17 time: 311.3339
[2021-11-12 15:06:21] epoch[29](4000/20000) Loss: 1.4444 Acc@1: 66.85 Acc@5: 86.22 time: 305.2451
[2021-11-12 15:11:26] epoch[29](6000/20000) Loss: 1.4458 Acc@1: 66.85 Acc@5: 86.23 time: 305.5414
[2021-11-12 15:16:31] epoch[29](8000/20000) Loss: 1.4472 Acc@1: 66.81 Acc@5: 86.19 time: 305.0852
[2021-11-12 15:21:37] epoch[29](10000/20000) Loss: 1.4479 Acc@1: 66.83 Acc@5: 86.17 time: 305.6253
[2021-11-12 15:26:43] epoch[29](12000/20000) Loss: 1.4480 Acc@1: 66.81 Acc@5: 86.17 time: 305.3912
[2021-11-12 15:31:48] epoch[29](14000/20000) Loss: 1.4497 Acc@1: 66.77 Acc@5: 86.14 time: 305.3878
[2021-11-12 15:36:53] epoch[29](16000/20000) Loss: 1.4496 Acc@1: 66.77 Acc@5: 86.14 time: 304.9792
[2021-11-12 15:41:58] epoch[29](18000/20000) Loss: 1.4494 Acc@1: 66.77 Acc@5: 86.14 time: 305.4174
[2021-11-12 15:47:04] epoch[29](20000/20000) Loss: 1.4493 Acc@1: 66.78 Acc@5: 86.15 time: 305.3555
[2021-11-12 15:47:07] train    Loss: 1.4493 Acc@1: 66.78 Acc@5: 86.15 time: 3062.4909
[2021-11-12 15:48:23] validate Loss: 1.1998 Acc@1: 70.17 Acc@5: 89.85 time: 76.0849
[2021-11-12 15:48:23] storing pruned_model:/finally_pruned_model/resnet_50_1_fs.pt
[2021-11-12 15:49:31] validate Loss: 1.1998 Acc@1: 70.26 Acc@5: 89.82 time: 67.8522
[2021-11-12 15:49:31] finally model  Acc@1: 70.26 Acc@5: 89.82 flops: 978719700.0 params:8100543.0
